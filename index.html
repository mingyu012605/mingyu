<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI VR CAD Editor</title>
    <!-- Using Inter font from Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <style>
        /* Global Styles */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            font-family: 'Inter', sans-serif; /* Changed font to Inter */
            background: #f0f2f5; /* Lighter, subtle background for overall app */
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }

        /* Header */
        header {
            background-color: #1a202c; /* Darker, more professional header */
            padding: 15px 25px;
            color: #e2e8f0; /* Lighter text for contrast */
            text-align: center;
            font-size: 2.2rem; /* Slightly smaller, more refined font size */
            font-weight: 700; /* Bolder font weight */
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            flex-shrink: 0;
            height: 70px; /* Slightly reduced height */
            box-sizing: border-box;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2); /* Subtle shadow for depth */
        }

        header svg {
            height: 35px; /* Slightly smaller icon */
            width: 35px;
            fill: #007bff; /* Accent color for the logo */
            transition: transform 0.3s ease; /* Smooth transition for hover effect */
        }

        header:hover svg {
            transform: rotate(5deg) scale(1.05); /* Slight rotation and scale on hover */
        }

        /* Page Container & Transitions */
        .page-container {
            display: flex;
            flex-direction: column;
            flex-grow: 1;
            width: 100%;
            position: relative;
        }

        .page {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            transition: opacity 0.6s ease-in-out, transform 0.6s ease-in-out; /* Smoother transitions */
            transform: translateX(0); /* Default position */
        }

        .page-active {
            opacity: 1;
            pointer-events: auto;
            z-index: 1;
        }

        .page-inactive {
            opacity: 0;
            pointer-events: none;
            z-index: 0;
            transform: translateX(-100%); /* Slide out to the left */
        }

        /* Upload Page */
        #uploadPage {
            background-color: #f0f2f5; /* Consistent with body background */
            color: #333;
            padding: 20px; /* Add some padding */
            box-sizing: border-box;
        }

        .upload-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 25px; /* Increased gap for better spacing */
            background: #ffffff;
            padding: 50px 60px; /* More generous padding */
            border-radius: 15px; /* More rounded corners */
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.15); /* Stronger, softer shadow */
            width: 90%; /* Responsive width */
            max-width: 500px; /* Max width for larger screens */
            text-align: center;
        }

        .upload-content h2 {
            color: #1a202c;
            margin-bottom: 15px; /* Adjusted margin */
            font-size: 2.2em; /* Slightly larger heading */
            font-weight: 700;
        }

        #dropZone {
            width: 100%; /* Full width within its container */
            height: 180px; /* Taller drop zone */
            border: 3px dashed #a0aec0; /* Thicker, slightly darker dashed border */
            border-radius: 10px;
            display: flex;
            justify-content: center;
            align-items: center;
            text-align: center;
            color: #4a5568; /* Darker text */
            cursor: pointer;
            transition: border-color 0.4s ease, background-color 0.4s ease, color 0.4s ease;
            font-size: 1.2em; /* Larger font size */
            background-color: #f7fafc; /* Slightly off-white background */
            font-weight: 600;
            position: relative; /* Needed for absolute positioning of fileInput */
            overflow: hidden; /* Hide overflow of fileInput */
        }

        #dropZone:hover {
            border-color: #007bff; /* Accent color on hover */
            background-color: #e6f0ff; /* Light blue background on hover */
            color: #0056b3;
        }

        #fileInput {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            opacity: 0; /* Make it transparent */
            cursor: pointer;
            z-index: 2; /* Ensure it's above the dropZone text */
        }

        .button-group {
            display: flex;
            gap: 20px; /* Increased gap between buttons */
            margin-top: 25px;
        }

        .button {
            padding: 14px 30px; /* Larger padding */
            border: none;
            border-radius: 8px; /* More rounded buttons */
            cursor: pointer;
            font-size: 1.1em; /* Slightly larger font */
            font-weight: 600; /* Bolder text */
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Subtle button shadow */
        }

        .button.primary {
            background-color: #007bff;
            color: white;
        }

        .button.primary:hover {
            background-color: #0056b3;
            transform: translateY(-3px); /* More pronounced lift */
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2);
        }

        .button.secondary {
            background-color: #6c757d;
            color: white;
        }

        .button.secondary:hover {
            background-color: #5a6268;
            transform: translateY(-3px);
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2);
        }

        #loadingMsg {
            display: none;
            margin-top: 25px; /* Adjusted margin */
            color: #007bff;
            font-size: 1.15em; /* Slightly larger font */
            font-weight: 600;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.05); /* Very subtle text shadow */
        }

        /* Editor Page */
        #editorPage {
            background-color: #2d3748; /* Darker, more immersive background for editor */
            flex-direction: row;
            justify-content: flex-start;
            align-items: stretch;
            padding: 0;
            box-sizing: border-box;
        }

        .sidebar {
            width: 300px; /* Slightly wider sidebar */
            background-color: #1a202c; /* Darker sidebar background */
            padding: 25px; /* More padding */
            display: flex;
            flex-direction: column;
            border-right: 1px solid #2d3748; /* Darker border */
            box-shadow: 4px 0 10px rgba(0, 0, 0, 0.3); /* Stronger shadow for sidebar */
            flex-shrink: 0;
            overflow-y: auto;
            color: #e2e8f0; /* Lighter text for sidebar */
        }

        .sidebar h2 {
            color: #ffffff; /* White heading */
            margin-bottom: 25px;
            font-size: 1.9em; /* Slightly larger heading */
            border-bottom: 2px solid #007bff; /* Accent color border */
            padding-bottom: 12px;
            font-weight: 700;
        }

        .editor-controls {
            display: flex;
            flex-direction: column;
            gap: 18px; /* Increased gap */
            margin-bottom: 35px;
        }

        .control-button {
            width: 100%;
            padding: 14px; /* Larger padding */
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 8px; /* More rounded buttons */
            cursor: pointer;
            font-size: 1.05em; /* Slightly larger font */
            font-weight: 600;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            box-shadow: 0 3px 6px rgba(0, 0, 0, 0.15);
        }

        .control-button:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0, 0, 0, 0.25);
        }

        .control-button svg {
            fill: white;
            height: 22px; /* Slightly larger icons */
            width: 22px;
        }

        #cadViewer {
            flex-grow: 1;
            background-color: #2d3748; /* Consistent with editor background */
            position: relative;
        }

        #cadCanvas {
            display: block;
            width: 100%;
            height: 100%;
        }

        /* AI Interaction Panel */
        #aiInteractionPanel {
            background-color: #1a202c; /* Same as sidebar background */
            border-top: 1px solid #2d3748; /* Darker border */
            padding: 20px;
            display: flex;
            flex-direction: column;
            gap: 15px; /* Increased gap */
            flex-shrink: 0;
            height: auto;
            max-height: 45%; /* Slightly more height for chat */
            overflow: hidden;
            transition: all 0.4s ease-in-out; /* Smoother transition */
            position: absolute;
            bottom: 0;
            width: 100%;
            left: 0;
            box-sizing: border-box;
            transform: translateY(100%);
            opacity: 0;
            box-shadow: 0 -4px 10px rgba(0, 0, 0, 0.3); /* Shadow for the panel */
        }

        #aiInteractionPanel.active {
            transform: translateY(0);
            opacity: 1;
            max-height: 80%; /* Can expand further if needed */
        }


        #aiLog {
            flex-grow: 1;
            background-color: #2d3748; /* Darker background for log */
            border-radius: 10px; /* Rounded corners for log */
            padding: 15px;
            color: #e2e8f0; /* Light text for readability */
            overflow-y: auto;
            height: 180px; /* Increased default height */
            flex-shrink: 1;
            line-height: 1.5; /* Better line spacing */
        }

        #aiLog p {
            margin: 7px 0; /* Adjusted margin */
            padding: 5px 10px;
            border-radius: 6px;
        }

        .user-message {
            background-color: #007bff; /* Accent color for user messages */
            color: white;
            text-align: right;
            align-self: flex-end; /* Align to the right */
            max-width: 80%; /* Limit width */
            margin-left: auto; /* Push to right */
        }

        .ai-response {
            background-color: #4a5568; /* Darker grey for AI responses */
            color: #e2e8f0;
            text-align: left;
            align-self: flex-start; /* Align to the left */
            max-width: 80%;
            margin-right: auto;
        }

        .system-message {
            background-color: #2d3748; /* Background for system messages */
            color: #cbd5e0; /* Lighter grey for system messages */
            text-align: center;
            font-style: italic;
            border-bottom: 1px dashed #4a5568; /* Subtle separator */
            padding-bottom: 10px;
            margin-bottom: 10px;
        }

        .ai-input-group {
            display: flex;
            gap: 10px;
            flex-shrink: 0;
        }

        #textCommandInput {
            flex-grow: 1;
            padding: 12px; /* Larger padding */
            border: 1px solid #4a5568; /* Darker border */
            border-radius: 8px; /* Rounded corners */
            background-color: #2d3748; /* Dark background */
            color: #e2e8f0; /* Light text */
            font-size: 1em;
            outline: none; /* Remove default outline */
            box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.3); /* Inner shadow */
        }

        #textCommandInput::placeholder {
            color: #a0aec0; /* Lighter placeholder text */
        }

        #textCommandInput:focus {
            border-color: #007bff; /* Accent color on focus */
            box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.3), 0 0 0 2px rgba(0, 123, 255, 0.3); /* Focus ring */
        }

        #sendTextCommandBtn {
            padding: 12px 20px; /* Consistent padding */
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            box-shadow: 0 3px 6px rgba(0, 0, 0, 0.15);
        }

        #sendTextCommandBtn:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0, 0, 0, 0.25);
        }

        #voiceAssistBtn {
            background-color: #4a5568; /* Darker grey for voice button */
            border: none;
            border-radius: 10px; /* More rounded */
            padding: 18px 25px; /* Larger padding */
            font-size: 1.15em;
            font-weight: 700;
            color: white;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            position: absolute;
            bottom: 30px; /* More space from bottom */
            right: 30px; /* More space from right */
            display: flex;
            align-items: center;
            gap: 12px;
            z-index: 10;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.25); /* Stronger shadow */
        }

        #voiceAssistBtn:hover {
            background-color: #2d3748; /* Even darker on hover */
            transform: translateY(-4px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.35);
        }

        #voiceAssistBtn.active-voice-btn {
            background-color: #e53e3e; /* Red for active state */
            box-shadow: 0 5px 15px rgba(229, 62, 62, 0.4); /* Red glow */
        }

        #voiceAssistBtn.active-voice-btn:hover {
            background-color: #c53030;
            transform: translateY(-4px);
            box-shadow: 0 8px 20px rgba(229, 62, 62, 0.5);
        }
    </style>
    <!-- Import Map for ES Modules -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/"
            }
        }
    </script>
</head>
<body>
    <header>
        <!-- New Innovative Logo SVG -->
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
            <path d="M12 1L2 6v12l10 5 10-5V6L12 1zm0 2.31L18.47 6 12 9.31 5.53 6 12 3.31zM4 7.69l6 3.15v6.52L4 13.84V7.69zm8 11.01L6.47 16 12 12.69l5.53 3.31L12 18.7zM20 13.84l-6 3.15V10.84l6-3.15v6.15z"/>
            <circle cx="12" cy="12" r="2" fill="#007bff"/>
            <path d="M12 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z" fill="#fff"/>
        </svg>
        AI VR CAD Editor
    </header>

    <div class="page-container">
        <section id="uploadPage" class="page page-active">
            <div class="upload-content">
                <h2>Upload your 3D Model</h2>
                <!-- Removed onclick from dropZone; fileInput will handle clicks directly -->
                <div id="dropZone">
                    Drag and Drop your .gltf or .glb file(s) here
                    <input type="file" id="fileInput" accept=".gltf,.glb" />
                </div>
                <button class="button primary" id="loadEditorButton">Load Model & Go to Editor</button>
                <p id="loadingMsg">Loading model, please wait...</p>
            </div>
        </section>

        <section id="editorPage" class="page page-inactive">
            <aside class="sidebar">
                <h2>Controls</h2>
                <div class="editor-controls">
                    <button class="control-button" onclick="window.removeObject()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M6 19c0 1.1.9 2 2 2h8c1.1 0 2-.9 2-2V7H6v12zm2.46-7.12l1.41-1.41L12 12.59l2.12-2.12 1.41 1.41L13.41 14l2.12 2.12-1.41 1.41L12 15.41l-2.12 2.12-1.41-1.41L10.59 14l-2.13-2.12zM15.5 4l-1-1h-5l-1 1H5v2h14V4h-3.5z"/></svg>
                        Remove Object
                    </button>
                    <button class="control-button" onclick="window.resetView()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M12 4C7.31 4 3.07 5.9 0 8.98L12 21 24 8.98C20.93 5.9 16.69 4 12 4zm0 2.98c2.18 0 4.2.82 5.74 2.37L12 18.06 6.26 9.35C7.8 7.8 9.82 6.98 12 6.98z"/></svg>
                        Reset View
                    </button>
                    <button class="control-button" onclick="window.showDesignInfo()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M11 7h2v2h-2zm0 4h2v6h-2zm1-9C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8z"/></svg>
                        Design Info
                    </button>
                    <button class="control-button" onclick="window.goBack()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M12 2c5.52 0 10 4.48 10 10s-4.48 10-10 10S2 17.52 2 12 6.48 2 12 2zm0 18c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8zm-1-13v4H7.5L12 16.5 16.5 12H13V7z"/></svg>
                        Back to Upload
                    </button>
                </div>

                <h2>AI Chat Log</h2>
                <div id="aiLog">
                    <p class="system-message">System: AI Chat Log Initialized.</p>
                </div>
                <div class="ai-input-group">
                    <input type="text" id="textCommandInput" placeholder="Type AI command or question..." />
                    <button id="sendTextCommandBtn">Send</button>
                </div>
            </aside>

            <main id="cadViewer">
                <canvas id="cadCanvas"></canvas>
            </main>
            <button id="voiceAssistBtn">ðŸ§  AI Voice Assist</button>
            <div id="aiInteractionPanel"></div>
        </section>
    </div>

<script type="module">
    // Import Three.js and its modules
    import * as THREE from 'three';
    import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
    import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
    import { VRButton } from 'three/addons/webxr/VRButton.js';

    // Global map to store dropped files by their relative path (e.g., "scene.bin", "textures/image.png")
    const droppedFileBlobs = new Map();

    let uploadedFile = null, scene, camera, renderer, mesh, controls;
    let recognition;
    let synth;
    let isVoiceAssistActive = false;
    let raycaster;
    let mouse;
    let selectedObject = null; // This will hold the currently selected THREE.Mesh part
    const originalMaterials = new Map(); // Map to store original materials by object UUID

    // Get references to HTML elements
    const fileInput = document.getElementById('fileInput');
    const dropZone = document.getElementById('dropZone');
    const loadingMsg = document.getElementById('loadingMsg');
    const uploadPage = document.getElementById('uploadPage');
    const editorPage = document.getElementById('editorPage');
    const voiceAssistBtn = document.getElementById('voiceAssistBtn');
    const aiInteractionPanel = document.getElementById('aiInteractionPanel');
    const aiLog = document.getElementById('aiLog');
    const textCommandInput = document.getElementById('textCommandInput');
    const sendTextCommandBtn = document.getElementById('sendTextCommandBtn');
    const cadCanvas = document.getElementById('cadCanvas'); // Reference to the canvas element
    const loadEditorButton = document.getElementById('loadEditorButton'); // Reference to the new button ID

    // --- File Input and Page Navigation ---
    // Removed the click listener from dropZone as fileInput will handle clicks directly
    dropZone.addEventListener('dragover', e => {
        e.preventDefault();
        dropZone.textContent = 'Release to drop your .gltf or .glb file(s)';
        dropZone.style.borderColor = '#007bff';
    });
    dropZone.addEventListener('dragleave', () => {
        dropZone.textContent = 'Drag and Drop your .gltf or .glb file(s) here';
        dropZone.style.borderColor = '#a0aec0'; // Reset to original color
    });
    dropZone.addEventListener('drop', async e => {
        e.preventDefault();
        dropZone.textContent = 'Processing files...';
        dropZone.style.borderColor = '#a0aec0'; // Reset to original color
        loadingMsg.textContent = 'Processing dropped files...';
        loadingMsg.style.color = '#007bff';
        loadingMsg.style.display = 'block';

        droppedFileBlobs.clear(); // Clear previous files
        let mainModelFile = null;

        console.log("[Drop Handler] Drop event detected. Items:", e.dataTransfer.items);
        console.log("[Drop Handler] Files:", e.dataTransfer.files);

        // Function to recursively read directory entries
        async function readDroppedFiles(entry, path) {
            if (entry.isFile) {
                const file = await new Promise(resolve => entry.file(resolve));
                const fullPath = path ? `${path}/${file.name}` : file.name;
                droppedFileBlobs.set(fullPath, file);
                console.log(`[Drop Handler] Stored file: ${fullPath}, Type: ${file.type}, Size: ${file.size} bytes`); // Debugging
                if (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb')) {
                    mainModelFile = file;
                }
            } else if (entry.isDirectory) {
                const directoryReader = entry.createReader();
                const entries = await new Promise(resolve => directoryReader.readEntries(resolve));
                console.log(`[Drop Handler] Reading directory: ${path ? `${path}/${entry.name}` : entry.name}, Entries found: ${entries.length}`);
                for (const subEntry of entries) {
                    await readDroppedFiles(subEntry, path ? `${path}/${entry.name}` : entry.name);
                }
            }
        }

        // Check if DataTransferItem.webkitGetAsEntry is available (for folder drops)
        if (e.dataTransfer.items && e.dataTransfer.items.length > 0 && e.dataTransfer.items[0].webkitGetAsEntry) {
            console.log("[Drop Handler] Using webkitGetAsEntry for folder drop detection.");
            for (let i = 0; i < e.dataTransfer.items.length; i++) {
                const item = e.dataTransfer.items[i];
                const entry = item.webkitGetAsEntry();
                if (entry) {
                    await readDroppedFiles(entry, ''); // Start recursive read from root
                }
            }
        } else {
            console.log("[Drop Handler] Falling back to flat file drop (webkitGetAsEntry not available or not a folder drop).");
            // Fallback for browsers that's don't support webkitGetAsEntry or if only files are dropped
            for (let i = 0; i < e.dataTransfer.files.length; i++) {
                const file = e.dataTransfer.files[i];
                droppedFileBlobs.set(file.name, file);
                console.log(`[Drop Handler] Stored file (flat): ${file.name}, Type: ${file.type}, Size: ${file.size} bytes`); // Debugging
                if (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb')) {
                    mainModelFile = file;
                }
            }
        }

        if (mainModelFile) {
            uploadedFile = mainModelFile; // Set the main model file
            console.log("[Drop Handler] Identified main model file:", uploadedFile.name);
            validateFile(uploadedFile); // Validate and proceed
            console.log("[Drop Handler] All dropped files (keys in map):", Array.from(droppedFileBlobs.keys()));
        } else {
            loadingMsg.textContent = 'âŒ No .gltf or .glb file found among dropped items!';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            uploadedFile = null;
            console.error("[Drop Handler] No GLTF/GLB file found in dropped items.");
        }
        console.log("[Drop Handler] uploadedFile after drop processing:", uploadedFile ? uploadedFile.name : "null");
    });

    fileInput.addEventListener('change', () => {
        console.log("[File Input] Change event detected. Files:", fileInput.files);
        // For file input, we only get one file, so it's simpler
        if (fileInput.files.length > 0) {
            loadingMsg.textContent = 'Processing selected file...';
            loadingMsg.style.color = '#007bff';
            loadingMsg.style.display = 'block';

            droppedFileBlobs.clear();
            const file = fileInput.files[0];
            droppedFileBlobs.set(file.name, file);
            uploadedFile = file;
            console.log("[File Input] Selected file:", uploadedFile.name, `Type: ${uploadedFile.type}, Size: ${uploadedFile.size} bytes`);
            validateFile(uploadedFile);
            console.log("[File Input] Dropped file (keys in map):", Array.from(droppedFileBlobs.keys()));
        } else {
            console.log("[File Input] No file selected via input.");
            uploadedFile = null;
            loadingMsg.textContent = 'No file selected. Please choose a .gltf or .glb file.';
            loadingMsg.style.color = 'orange';
            loadingMsg.style.display = 'block';
        }
        console.log("[File Input] uploadedFile after change processing:", uploadedFile ? uploadedFile.name : "null");
    });

    // Attach event listener for the "Load Model & Go to Editor" button
    loadEditorButton.addEventListener('click', goToEditor); // Correctly attach event listener

    function validateFile(file) {
        console.log("[Validation] Validating file:", file ? file.name : "null");
        if (file && (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb'))) {
            console.log("[Validation] File is a valid GLTF/GLB.");
            loadingMsg.textContent = `File selected: ${file.name}. Click 'Load Model & Go to Editor' or drop more files if needed.`;
            loadingMsg.style.color = '#007bff';
            loadingMsg.style.display = 'block';
            return true;
        } else {
            console.error("[Validation] Unsupported file type detected for:", file ? file.name : "null");
            loadingMsg.textContent = 'âŒ Unsupported file type! Please upload a .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            uploadedFile = null; // Ensure uploadedFile is null if validation fails
            return false;
        }
    }

    // Helper function to dispose Three.js resources
    function disposeSceneResources() {
        console.log("[Dispose] Disposing Three.js resources...");
        if (scene) {
            scene.traverse(function (object) {
                if (object.isMesh) {
                    if (object.geometry) object.geometry.dispose();
                    if (object.material) {
                        if (Array.isArray(object.material)) {
                            object.material.forEach(material => material.dispose());
                        } else {
                            material.dispose(); // Fixed: 'material' was undefined, should be 'object.material'
                        }
                    }
                }
            });
            scene = null; // Ensure scene is nulled out
        }
        if (renderer) {
            renderer.setAnimationLoop(null); // Stop animation loop
            renderer.dispose();
            renderer = null; // Ensure renderer is nulled out
        }
        if (controls) {
            controls.dispose();
            controls = null; // Ensure controls are nulled out
        }
        // Remove event listeners from the canvas to prevent memory leaks
        if (cadCanvas) {
            cadCanvas.removeEventListener('mousedown', onCanvasClick, false);
            cadCanvas.removeEventListener('touchstart', onCanvasClick, false);
        }
        console.log("[Dispose] Resources disposed.");
    }


    function goToEditor() {
        console.log("[goToEditor] Attempting to go to editor.");
        console.log("[goToEditor] Current uploadedFile:", uploadedFile ? uploadedFile.name : "null");
        if (!uploadedFile) {
            addMessageToLog('System', "Please upload a valid .gltf or .glb file before continuing.");
            loadingMsg.textContent = 'Please upload a valid .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            console.warn("[goToEditor] No uploaded file found.");
            return;
        }

        uploadPage.classList.remove('page-active');
        uploadPage.classList.add('page-inactive');

        editorPage.classList.remove('page-inactive');
        editorPage.classList.add('page-active');

        loadingMsg.textContent = `Loading model: ${uploadedFile.name}...`;
        loadingMsg.style.color = '#007bff';
        loadingMsg.style.display = 'block';
        console.log(`[goToEditor] Transitioning to editor. Preparing to load model: ${uploadedFile.name}`);
        console.log(`[goToEditor] Current droppedFileBlobs keys:`, Array.from(droppedFileBlobs.keys()));


        // Dispose existing resources before initializing a new scene
        disposeSceneResources();
        // Re-initialize the scene every time we go to editor to ensure a clean state
        initScene();

        loadModel(uploadedFile); // Load model after transition
    }

    function goBack() {
        console.log("[Navigation] Going back to upload page.");
        editorPage.classList.remove('page-active');
        editorPage.classList.add('page-inactive');

        uploadPage.classList.remove('page-inactive');
        uploadPage.classList.add('page-active');

        stopVoiceAssist(); // Ensure voice assist is stopped when going back

        // IMPORTANT: Remove resize listener BEFORE disposing renderer
        window.removeEventListener('resize', onWindowResize, false);

        // Dispose of Three.js resources when navigating back
        disposeSceneResources(); // Call the helper function

        uploadedFile = null; // Clear the uploaded file
        droppedFileBlobs.clear(); // Clear the map of dropped files
        originalMaterials.clear(); // Clear original materials map
        selectedObject = null; // Clear selected object

        dropZone.style.borderColor = '#a0aec0'; // Reset drop zone style
        dropZone.textContent = 'Drag and Drop your .gltf or .glb file(s) here'; // Reset drop zone text
        loadingMsg.style.display = 'none'; // Hide loading message
        loadingMsg.style.color = ''; // Reset color
        console.log("[Navigation] Returned to upload page. State reset.");
    }

    // --- Three.js Scene Setup and Model Loading ---
    function initScene() {
        console.log("[initScene] Initializing Three.js scene...");
        // Add a debug check for THREE
        if (typeof THREE === 'undefined') {
            console.error("THREE is not defined at initScene! Three.js script might not have loaded or executed correctly.");
            addMessageToLog('System', "Error: Three.js library failed to load. Please check console for details.");
            return; // Prevent further errors
        }

        scene = new THREE.Scene();
        scene.background = new THREE.Color(0x222222); // Dark background

        const viewerDiv = cadCanvas.parentElement;
        const width = viewerDiv.clientWidth;
        const height = viewerDiv.clientHeight;

        camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
        camera.position.set(0, 0, 50); // Initial camera position

        renderer = new THREE.WebGLRenderer({ canvas: cadCanvas, antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(width, height);
        renderer.xr.enabled = true; // Enable WebXR for VR

        // OrbitControls is now globally available
        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.25;

        // Lighting
        const ambientLight = new THREE.AmbientLight(0x404040); // Soft white light
        scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
        directionalLight.position.set(1, 1, 1).normalize();
        scene.add(directionalLight);

        // VR Button is now globally available
        // document.body.appendChild(VRButton.createButton(renderer));

        // Raycasting for selection
        raycaster = new THREE.Raycaster();
        mouse = new THREE.Vector2();

        // Attach event listeners for selection after renderer is set up
        renderer.domElement.addEventListener('mousedown', onCanvasClick, false);
        renderer.domElement.addEventListener('touchstart', onCanvasClick, false);

        console.log("[initScene] Three.js scene initialized.");
        animate(); // Start the animation loop
    }

    function animate() {
        // Use renderer.setAnimationLoop for WebXR compatibility
        renderer.setAnimationLoop(() => {
            controls.update();
            renderer.render(scene, camera);
        });
    }

    function loadModel(file) {
        console.log("[loadModel] Attempting to load file:", file.name);
        // GLTFLoader is now globally available
        const loader = new GLTFLoader();

        // Custom FileLoader with a resolver for dropped files
        const fileLoader = new THREE.FileLoader();
        fileLoader.manager = new THREE.LoadingManager();
        fileLoader.manager.setURLModifier(url => {
            console.log(`[URLModifier] Requested URL: "${url}"`);
            // Attempt to resolve relative paths within the droppedFileBlobs map
            const fileName = url.split('/').pop(); // Get just the filename
            let resolvedPath = fileName; // Default to just filename

            // If the URL is a blob URL, try to find it in the map
            if (url.startsWith('blob:')) {
                // This is tricky as blob URLs are unique. We need to find the original file name.
                // For now, if it's a blob, we assume it's the main model file itself or an embedded resource.
                // The GLTFLoader's parse method handles embedded data.
                // For external files referenced by name, we need to search our map.
                const blobFile = Array.from(droppedFileBlobs.values()).find(f => URL.createObjectURL(f) === url);
                if (blobFile) {
                    resolvedPath = blobFile.name;
                    console.log(`[URLModifier] Resolved blob URL to file: ${resolvedPath}`);
                }
            } else {
                // For relative paths in GLTF, try to find them in our map
                // This is a simplified approach; a real GLTF resolver needs to handle base paths carefully
                const potentialPaths = Array.from(droppedFileBlobs.keys()).filter(key => key.endsWith(fileName));
                if (potentialPaths.length > 0) {
                    // Prefer exact match or shortest path if multiple exist
                    resolvedPath = potentialPaths.sort((a, b) => a.length - b.length)[0];
                    console.log(`[URLModifier] Resolved relative path to: ${resolvedPath}`);
                }
            }

            const foundFile = droppedFileBlobs.get(resolvedPath);
            if (foundFile) {
                const blobURL = URL.createObjectURL(foundFile);
                console.log(`[URLModifier] Returning Blob URL for ${resolvedPath}: ${blobURL}`);
                return blobURL;
            } else {
                console.warn(`[URLModifier] GLTFLoader could not find referenced file: "${url}" (tried "${resolvedPath}", and potentially combined paths). Falling back to original URL.`);
                return url; // Fallback to original URL if not found in our map
            }
        });

        const reader = new FileReader();

        reader.onload = (event) => {
            const contents = event.target.result;
            console.log(`[FileReader] ${file.name} read successfully.`);

            // Use the custom fileLoader.manager for GLTFLoader
            loader.manager = fileLoader.manager;

            loader.parse(contents, '', (gltf) => {
                console.log("[GLTFLoader] .gltf/.glb parsing successful.");
                // Remove existing model if any
                if (mesh) {
                    scene.remove(mesh);
                    mesh.traverse(obj => {
                        if (obj.isMesh) {
                            if (obj.geometry) obj.geometry.dispose();
                            if (obj.material) {
                                if (Array.isArray(obj.material)) {
                                    obj.material.forEach(m => m.dispose());
                                } else {
                                    obj.material.dispose();
                                }
                            }
                        }
                    });
                }
                clearSelection(); // Clear any previous selection

                mesh = gltf.scene; // The glTF scene is the main container for all objects
                scene.add(mesh);
                console.log("[GLTFLoader] gltf.scene object:", mesh);
                console.log("[GLTFLoader] gltf.scene children count:", mesh.children.length);

                // Center and scale the model
                const bbox = new THREE.Box3().setFromObject(mesh);
                const center = bbox.getCenter(new THREE.Vector3());
                mesh.position.sub(center); // Center the model's group

                const size = bbox.getSize(new THREE.Vector3());
                const maxDim = Math.max(size.x, size.y, size.z);
                const desiredMaxDim = 40; // Target size for the model in the scene
                const scaleFactor = desiredMaxDim / maxDim;
                mesh.scale.set(scaleFactor, scaleFactor, scaleFactor);

                // Adjust camera to fit the new model
                const newBbox = new THREE.Box3().setFromObject(mesh); // Get bbox after scaling
                const newSize = newBbox.getSize(new THREE.Vector3());
                const newMaxDim = Math.max(newSize.x, newSize.y, newSize.z);
                camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
                camera.lookAt(0, 0, 0);
                controls.update(); // Update controls after camera change

                loadingMsg.style.display = 'none';
                addMessageToLog('System', `Model '${file.name}' loaded successfully.`);
                speakResponse(`Model loaded successfully.`);
                console.log("[loadModel] Model successfully added to scene.");

            }, (xhr) => {
                // Progress during loading
                loadingMsg.textContent = `Loading ${file.name}: ${Math.round(xhr.loaded / xhr.total * 100)}%`;
            }, (error) => {
                console.error('An error happened loading the GLTF model:', error);
                addMessageToLog('System', 'Error loading model. Check console for details.');
                loadingMsg.textContent = 'Error loading model. Check console.';
                loadingMsg.style.color = 'red';
                loadingMsg.style.display = 'block';
                speakResponse('Error loading model.');
            });
        };

        if (file.name.toLowerCase().endsWith('.glb')) {
            console.log(`[loadModel] Handling .glb file: ${file.name}`);
            reader.readAsArrayBuffer(file); // GLTFLoader prefers ArrayBuffer for GLB
        } else if (file.name.toLowerCase().endsWith('.gltf')) {
            console.log(`[loadModel] Handling .gltf file: ${file.name}`);
            reader.readAsText(file); // GLTFLoader can parse JSON directly from text for GLTF
        } else {
            console.error(`[loadModel] Unsupported file type for loading: ${file.name}`);
            loadingMsg.textContent = 'Unsupported file type for loading. Please use .gltf or .glb.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
        }
    }

    window.addEventListener('resize', onWindowResize, false);

    function onWindowResize() {
        const viewerDiv = cadCanvas.parentElement;
        const width = viewerDiv.clientWidth;
        const height = viewerDiv.clientHeight;

        if (width > 0 && height > 0 && camera && renderer && controls) { // Added checks for camera, renderer, controls
            camera.aspect = width / height;
            camera.updateProjectionMatrix();
            renderer.setSize(width, height);
            controls.update();
        }
    }

    // Initialize scene when the window loads
    window.onload = () => {
        initScene();
        initializeSpeechSynthesis();
    };

    // --- CAD Editor Functions ---
    // Note: removeObject, resetView, showDesignInfo are updated to handle selectedObject or mesh
    function removeObject() {
        let targetObject = selectedObject || mesh; // Target selected object, or the whole model
        if (targetObject) {
            scene.remove(targetObject);
            // Dispose of its resources explicitly
            if (targetObject.geometry) {
                targetObject.geometry.dispose();
            }
            if (targetObject.material) {
                if (Array.isArray(targetObject.material)) {
                    targetObject.material.forEach(material => material.dispose());
                } else {
                    targetObject.material.dispose();
                }
            }
            
            if (targetObject === mesh) { // If main model was removed
                mesh = null;
                addMessageToLog('AI', "Model removed.");
                speakResponse("Model removed.");
                // Go back to upload page if main model is removed
                goBack(); // This will also clear selection
            } else { // If a specific part was removed
                addMessageToLog('AI', `Part '${targetObject.name || 'unnamed part'}' removed.`);
                speakResponse(`Part removed.`);
                clearSelection(); // Clear selection after removal
            }
        } else {
            addMessageToLog('AI', "No object or part to remove.");
            speakResponse("No object or part to remove.");
        }
    }

    function resetView() {
        if (mesh) { // Resetting view always applies to the whole loaded model
            mesh.rotation.set(0, 0, 0); // Reset rotation of the main model
            mesh.position.set(0, 0, 0); // Reset position of the main model

            // Recenter and re-frame camera
            const bbox = new THREE.Box3().setFromObject(mesh);
            const center = bbox.getCenter(new THREE.Vector3());
            mesh.position.sub(center); // Center the model's group

            const size = bbox.getSize(new THREE.Vector3());
            const maxDim = Math.max(size.x, size.y, size.z);
            camera.position.set(maxDim * 1.5, maxDim * 1.5, maxDim * 1.5); // Corrected to maxDim
            camera.lookAt(0, 0, 0);
            controls.update();
            addMessageToLog('AI', "View reset.");
            speakResponse("View reset.");
        } else {
            addMessageToLog('AI', "No model to reset view for.");
            speakResponse("No model to reset view for.");
        }
    }

    function showDesignInfo() {
        let targetObject = selectedObject || mesh; // Get info for selected object or whole model
        if (!targetObject) {
            addMessageToLog('AI', "No design loaded or part selected.");
            speakResponse("No design loaded or part selected.");
            return;
        }
        const bbox = new THREE.Box3().setFromObject(targetObject);
        const size = new THREE.Vector3();
        bbox.getSize(size);
        const info = `Name: ${targetObject.name || 'Unnamed'}\n` +
                     `Width: ${size.x.toFixed(2)}\nHeight: ${size.y.toFixed(2)}\nDepth: ${size.z.toFixed(2)}\n` +
                     `Position: X:${targetObject.position.x.toFixed(2)}, Y:${targetObject.position.y.toFixed(2)}, Z:${targetObject.position.z.toFixed(2)}`;
        addMessageToLog('AI', info.replace(/\n/g, ', '));
        speakResponse(info);
    }

    // --- Raycasting and Selection ---
    function onCanvasClick(event) {
        // Calculate mouse position in normalized device coordinates (-1 to +1)
        const rect = renderer.domElement.getBoundingClientRect();
        if (event.changedTouches) { // Handle touch events
            mouse.x = ((event.changedTouches[0].clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.changedTouches[0].clientY - rect.top) / rect.height) * 2 + 1;
        } else { // Handle mouse events
            mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
        }

        raycaster.setFromCamera(mouse, camera);

        // Intersect with all children of the main loaded glTF scene object (`mesh`)
        // This allows selecting individual parts/meshes if the glTF has them
        const intersects = raycaster.intersectObjects(mesh ? mesh.children : [], true); // Only intersect if mesh exists

        if (intersects.length > 0) {
            let clickedObject = null;
            for (const intersect of intersects) {
                // Ensure it's a visible mesh and not just a group or part of the background
                if (intersect.object.isMesh && intersect.object.visible && intersect.object.material) {
                    clickedObject = intersect.object;
                    break;
                }
            }

            if (clickedObject) {
                if (selectedObject && selectedObject !== clickedObject) {
                    // Restore original material of previously selected object
                    restoreOriginalMaterial(selectedObject);
                }

                if (selectedObject !== clickedObject) { // If a new object is selected
                    selectedObject = clickedObject;
                    storeAndHighlight(selectedObject);
                    addMessageToLog('System', `Object '${selectedObject.name || 'unnamed object'}' selected.`);
                    speakResponse(`Object selected.`);
                } else { // If the same object is clicked again, deselect it
                    clearSelection();
                }
            }
        } else {
            clearSelection(); // If clicked outside, clear selection
        }
    }

    function storeAndHighlight(object) {
        // Store a clone of the original material(s)
        if (Array.isArray(object.material)) {
            const originalMats = object.material.map(m => m.clone());
            originalMaterials.set(object.uuid, originalMats);
            object.material.forEach(m => m.color.set(0x00ff00)); // Green highlight
        } else if (object.material) {
            originalMaterials.set(object.uuid, object.material.clone());
            object.material.color.set(0x00ff00); // Green highlight
        }
    }

    function restoreOriginalMaterial(object) {
        const storedMaterial = originalMaterials.get(object.uuid);
        if (storedMaterial) {
            if (Array.isArray(object.material) && Array.isArray(storedMaterial)) {
                object.material.forEach((m, index) => {
                    if (storedMaterial[index]) {
                        m.copy(storedMaterial[index]); // Copy properties back
                    }
                });
            } else if (object.material && !Array.isArray(object.material) && storedMaterial && !Array.isArray(storedMaterial)) {
                object.material.copy(storedMaterial); // Copy properties back
            }
            originalMaterials.delete(object.uuid); // Clean up map entry
        }
    }

    function clearSelection() {
        if (selectedObject) {
            restoreOriginalMaterial(selectedObject);
            selectedObject = null;
            addMessageToLog('System', 'Selection cleared.');
            speakResponse('Selection cleared.');
        }
    }

    // --- AI Interaction Panel Functions ---
    function addMessageToLog(sender, message) {
        const p = document.createElement('p');
        p.textContent = `${sender}: ${message}`;
        p.classList.add(sender === 'User' ? 'user-message' : (sender === 'AI' ? 'ai-response' : 'system-message'));
        aiLog.appendChild(p);
        aiLog.scrollTop = aiLog.scrollHeight;
    }

    sendTextCommandBtn.addEventListener('click', () => {
        const command = textCommandInput.value.trim();
        if (command) {
            addMessageToLog('User', command);
            processAICommand(command);
            textCommandInput.value = '';
        }
    });

    textCommandInput.addEventListener('keypress', (event) => {
        if (event.key === 'Enter') {
            sendTextCommandBtn.click();
        }
    });

    // --- AI Voice Assist Functions ---
    voiceAssistBtn.addEventListener('click', toggleVoiceAssist);

    function initializeSpeechRecognition() {
        if (!('webkitSpeechRecognition' in window)) {
            addMessageToLog('System', "Speech recognition not supported in this browser. Please use Google Chrome.");
            return null;
        }
        const newRecognition = new webkitSpeechRecognition();
        newRecognition.continuous = true;
        newRecognition.interimResults = false;
        newRecognition.lang = 'en-US';
        return newRecognition;
    }

    function initializeSpeechSynthesis() {
        if (!('speechSynthesis' in window)) {
            addMessageToLog('System', "Speech synthesis not supported in this browser.");
            return null;
        }
        return window.speechSynthesis;
    }

    function speakResponse(text) {
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }
        synth.cancel();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'en-US';
        utterance.onend = () => {
            console.log('Speech synthesis ended');
            if (isVoiceAssistActive && recognition && !synth.speaking) {
                setTimeout(() => {
                    addMessageToLog('System', "Listening...");
                    recognition.start();
                }, 1500);
            }
        };
        utterance.onerror = (event) => {
            console.error('Speech synthesis error:', event);
            addMessageToLog('System', "Error speaking response.");
        };
        synth.speak(utterance);
    }

    function toggleVoiceAssist() {
        if (!mesh) {
            addMessageToLog('AI', "Please load a 3D model first.");
            speakResponse("Please load a 3D model first.");
            return;
        }

        if (!recognition) {
            recognition = initializeSpeechRecognition();
            if (!recognition) return;
        }
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }

        if (isVoiceAssistActive) {
            stopVoiceAssist();
            speakResponse("Voice assist stopped. Goodbye!");
        } else {
            isVoiceAssistActive = true;
            voiceAssistBtn.classList.add('active-voice-btn');
            voiceAssistBtn.innerHTML = 'âŒ Stop AI Voice';
            aiInteractionPanel.classList.add('active');
            addMessageToLog('System', "Starting voice assist...");

            speakResponse("Hi, what can I help you with?");
        }

        recognition.onstart = function () {
            addMessageToLog('System', "Listening...");
            console.log('Speech recognition started');
        };

        recognition.onresult = function (event) {
            const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
            addMessageToLog('User', transcript);
            addMessageToLog('System', "Processing voice command...");
            console.log('Speech recognized:', transcript);

            recognition.stop();
            processAICommand(transcript);
        };

        recognition.onerror = function (event) {
            console.error('Speech recognition error:', event);
            let errorMessage = "An unknown speech recognition error occurred.";
            if (event.error === 'not-allowed') {
                errorMessage = "Microphone access denied. Please allow microphone access in your browser settings.";
            } else if (event.error === 'no-speech') {
                errorMessage = "No speech detected. Please try speaking louder or clearer.";
            } else if (event.error) {
                errorMessage = `Speech error: ${event.error}. Please try again.`;
            }
            addMessageToLog('System', errorMessage);
            speakResponse(errorMessage);
            stopVoiceAssist();
        };

        recognition.onend = function () {
            console.log('Speech recognition ended');
        };
    }

    function stopVoiceAssist() {
        isVoiceAssistActive = false;
        if (recognition && typeof recognition.stop === 'function') {
            recognition.stop();
        }
        if (synth && typeof synth.cancel === 'function') {
            synth.cancel();
        }
        aiInteractionPanel.classList.remove('active');
        voiceAssistBtn.classList.remove('active-voice-btn');
        voiceAssistBtn.innerHTML = 'ðŸ§  AI Voice Assist';
        addMessageToLog('System', "Voice assist stopped.");
    }

    // --- AI Command Processing (Core Logic) ---
    async function processAICommand(command) {
        // Handle pre-defined UI commands first
        if (command.includes("select object") || command.includes("select part")) {
            if (selectedObject) {
                speakResponse("An object is already selected. Click on a different part to change selection or click outside to clear.");
            } else if (mesh) {
                speakResponse("Please click on a part of the model to select it.");
            } else {
                speakResponse("No model loaded to select.");
            }
            return;
        } else if (command.includes("clear selection") || command.includes("deselect")) {
            clearSelection();
            speakResponse("Selection cleared.");
            return;
        }

        try {
            const aiReply = await sendToAI(command);
            console.log("Raw AI response from backend:", aiReply);

            let resultData;
            try {
                // Ensure we're parsing the 'content' field from the backend response
                resultData = JSON.parse(aiReply.content);
                console.log("Parsed AI command:", resultData);
            } catch (e) {
                console.warn("AI response content was not valid JSON. Treating as conversational. Raw content:", aiReply.content, "Error:", e);
                // If parsing fails, treat the content as a conversational message
                resultData = { action: 'conversational', value: aiReply.content };
                console.log("Parsed AI conversational response:", resultData);
            }

            if (resultData && typeof resultData === 'object' && resultData.action) {
                let target = selectedObject || mesh; // Target the selected object, or the whole model if nothing is selected

                // Handle cases where an action requires a selected object but none is present
                const requiresSelection = ['rotateSelected', 'scaleSelected', 'translateSelected', 'colorSelected', 'hideSelected', 'showSelected', 'duplicateSelected', 'removeSelected'];
                if (requiresSelection.includes(resultData.action) && !selectedObject) {
                    addMessageToLog('AI', "Please select a part of the model first to perform that action.");
                    speakResponse("Please select a part of the model first to perform that action.");
                    return;
                }

                switch (resultData.action) {
                    case 'rotate':
                    case 'rotateSelected':
                        if (target && typeof resultData.value === 'number') {
                            // THREE.MathUtils.degToRad is now directly available via THREE
                            target.rotation.y += THREE.MathUtils.degToRad(resultData.value);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} rotated by ${resultData.value} degrees.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} rotated by ${resultData.value} degrees.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't rotate. Please specify a valid degree value or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't rotate.");
                        }
                        break;
                    case 'scale':
                    case 'scaleSelected':
                        if (target && typeof resultData.value === 'number' && resultData.value > 0) {
                            // Apply scale to X, Y, Z consistently
                            target.scale.set(resultData.value, resultData.value, resultData.value);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} scaled by a factor of ${resultData.value}.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} scaled by a factor of ${resultData.value}.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't scale. Please specify a positive scale factor or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't scale.");
                        }
                        break;
                    case 'translate':
                    case 'translateSelected':
                        if (target && typeof resultData.value === 'object' &&
                            !isNaN(resultData.value.x) && !isNaN(resultData.value.y) && !isNaN(resultData.value.z)) {
                            target.position.x += resultData.value.x || 0;
                            target.position.y += resultData.value.y || 0;
                            target.position.z += resultData.value.z || 0;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} moved by X:${resultData.value.x || 0}, Y:${resultData.value.y || 0}, Z:${resultData.value.z || 0} units.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} moved.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't move. Please specify valid X, Y, and Z values or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't move.");
                        }
                        break;
                    case 'color':
                    case 'colorSelected':
                        if (target && typeof resultData.value === 'string' && /^#([0-9A-F]{3}){1,2}$/i.test(resultData.value)) {
                            if (Array.isArray(target.material)) {
                                target.material.forEach(m => m.color.set(resultData.value));
                            } else if (target.material) {
                                target.material.color.set(resultData.value);
                            }
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} color changed to ${resultData.value}.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} color changed.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't change the color. Please provide a valid hexadecimal color code, or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't change the color.");
                        }
                        break;
                    case 'hide':
                    case 'hideSelected':
                        if (target) {
                            target.visible = false;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} is now hidden.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} is now hidden.`);
                            if (selectedObject === target) clearSelection(); // Deselect if hidden
                        } else {
                            addMessageToLog('AI', "No model or part to hide.");
                            speakResponse("No model or part to hide.");
                        }
                        break;
                    case 'show':
                    case 'showSelected':
                        if (target) {
                            target.visible = true;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} is now visible.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} is now visible.`);
                        } else {
                            addMessageToLog('AI', "No model or part to show.");
                            speakResponse("No model or part to show.");
                        }
                        break;
                    case 'duplicate':
                    case 'duplicateSelected':
                        if (target) {
                            const newObject = target.clone();
                            newObject.position.x += 10; // Offset slightly
                            newObject.position.y += 10;
                            scene.add(newObject);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} duplicated.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} duplicated.`);
                        } else {
                            addMessageToLog('AI', "No model or part to duplicate.");
                            speakResponse("No model or part to duplicate.");
                        }
                        break;
                    case 'removeObject':
                    case 'removeSelected': // AI might send this for selected object
                        removeObject(); // This function now handles selectedObject vs mesh
                        break;
                    case 'resetView': // This command always applies to the whole scene
                        resetView();
                        break;
                    case 'designInfo': // This command always applies to selected or whole model
                        showDesignInfo();
                        break;
                    case 'conversational':
                        let responseText = resultData.value || resultData.message;
                        if (responseText) {
                            addMessageToLog('AI', responseText);
                            speakResponse(responseText);
                        } else {
                            addMessageToLog('AI', "I received a conversational response but it was empty.");
                            speakResponse("I received a conversational response but it was empty.");
                        }
                        break;
                    case 'error':
                        addMessageToLog('AI', `An AI error occurred: ${resultData.value}. Please try again.`);
                        speakResponse("An error occurred with the AI. Please try again.");
                        console.error("AI returned an error action:", resultData.value);
                        break;
                    default:
                        addMessageToLog('AI', "The AI sent an unrecognized command. Please try again.");
                        speakResponse("The AI sent an unrecognized command. Please try again.");
                        console.warn("AI sent unrecognized action:", resultData.action);
                        break;
                }
            } else {
                addMessageToLog('AI', "I received an unexpected AI response. Please try again.");
                speakResponse("I received an unexpected AI response. Please try again.");
                console.error("Unexpected AI response format:", resultData);
            }
        } catch (error) {
            console.error("Error processing AI command:", error);
            addMessageToLog('AI', "I'm sorry, I encountered an error while processing your command. Please try again.");
            speakResponse("I'm sorry, I encountered an error. Please try again.");
        }
    }

    async function sendToAI(prompt) {
        sendTextCommandBtn.disabled = true;
        textCommandInput.disabled = true;
        addMessageToLog('System', 'AI is thinking...');

        const payload = {
            prompt: prompt
        };

        try {
            const response = await fetch('https://mingyu.onrender.com/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`Backend error: ${errorData.message || response.statusText}`);
            }

            const result = await response.json();
            return result;

        } catch (error) {
            console.error("Error communicating with backend AI:", error);
            return { content: `Failed to communicate with AI: ${error.message}` };
        } finally {
            sendTextCommandBtn.disabled = false;
            textCommandInput.disabled = false;
            const lastLogMessage = aiLog.lastChild;
            if (lastLogMessage && lastLogMessage.textContent.includes('AI is thinking...')) {
                aiLog.removeChild(lastLogMessage);
            }
        }
    }
</script>
</body>
</html>
