<script>
    let uploadedFile = null, scene, camera, renderer, mesh, controls;
    let recognition;
    let synth;
    let isVoiceAssistActive = false;
    let raycaster;
    let mouse;
    let selectedObject = null;
    let originalMaterialColor = null;

    const fileInput = document.getElementById('fileInput');
    const dropZone = document.getElementById('dropZone');
    const loadingMsg = document.getElementById('loadingMsg');
    const uploadPage = document.getElementById('uploadPage');
    const editorPage = document.getElementById('editorPage');
    const voiceAssistBtn = document.getElementById('voiceAssistBtn');

    // New AI Panel Elements
    const aiInteractionPanel = document.getElementById('aiInteractionPanel');
    const aiLog = document.getElementById('aiLog');
    const textCommandInput = document.getElementById('textCommandInput');
    const sendTextCommandBtn = document.getElementById('sendTextCommandBtn');


    dropZone.addEventListener('click', () => fileInput.click());
    dropZone.addEventListener('dragover', e => { e.preventDefault(); dropZone.textContent = 'Drop your .stl file here'; }); // Changed text
    dropZone.addEventListener('dragleave', () => dropZone.textContent = 'Drag and Drop your .stl file here');
    dropZone.addEventListener('drop', e => {
        e.preventDefault();
        uploadedFile = e.dataTransfer.files[0];
        validateFile(uploadedFile);
    });
    fileInput.addEventListener('change', e => {
        uploadedFile = e.target.files[0];
        validateFile(uploadedFile);
    });

    function validateFile(file) {
        if (file && file.name.toLowerCase().endsWith('.stl')) {
            dropZone.style.borderColor = '#28a745';
            dropZone.textContent = `âœ… File received: ${file.name}`;
        } else {
            dropZone.style.borderColor = 'red';
            dropZone.textContent = 'âŒ Unsupported file type! Please upload a .stl file.'; // More specific error
            uploadedFile = null;
        }
    }

    function goToEditor() {
        if (!uploadedFile) {
            // Use custom message box instead of alert
            addMessageToLog('System', "Please upload a valid .STL file before continuing.");
            return;
        }

        uploadPage.classList.remove('page-active');
        uploadPage.classList.add('page-inactive');

        editorPage.classList.remove('page-inactive');
        editorPage.classList.add('page-active');

        loadingMsg.style.display = 'block';

        loadSTLModel(uploadedFile);
    }

    function loadSTLModel(file) {
        // Dispose of existing Three.js objects to prevent memory leaks
        if (scene) {
            scene.traverse(function (object) {
                if (object.isMesh) {
                    if (object.geometry) object.geometry.dispose();
                    if (object.material) {
                        if (Array.isArray(object.material)) {
                            object.material.forEach(material => material.dispose());
                        } else {
                            object.material.dispose();
                        }
                    }
                }
            });
            scene = null;
        }
        if (renderer) {
            renderer.dispose();
            renderer = null;
        }
        if (controls) {
            controls.dispose();
            controls = null;
        }
        window.removeEventListener('resize', onWindowResize, false);
        // Remove canvas click listener if it was added
        const existingCanvas = document.getElementById('cadCanvas');
        if (existingCanvas) {
            existingCanvas.removeEventListener('mousedown', onCanvasClick, false);
            existingCanvas.removeEventListener('touchstart', onCanvasClick, false);
        }


        const reader = new FileReader();
        reader.onload = function (e) {
            const contents = e.target.result;
            const loader = new THREE.STLLoader();
            const geometry = loader.parse(contents);

            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x1e1f26); // Dark background for better contrast

            const canvas = document.getElementById('cadCanvas');
            const viewerDiv = canvas.parentElement;

            const width = viewerDiv.clientWidth;
            const height = viewerDiv.clientHeight;

            if (width === 0 || height === 0) {
                console.warn("Viewer dimensions are 0, model might not render correctly. Retrying in 100ms...");
                setTimeout(() => loadSTLModel(file), 100);
                return;
            }

            camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
            renderer.setSize(width, height);
            renderer.setPixelRatio(window.devicePixelRatio);

            window.addEventListener('resize', onWindowResize, false);

            // Add lights
            const light1 = new THREE.DirectionalLight(0xffffff, 0.8);
            light1.position.set(1, 1, 1).normalize();
            scene.add(light1);

            const light2 = new THREE.DirectionalLight(0xffffff, 0.5);
            light2.position.set(-1, -1, -1).normalize();
            scene.add(light2);

            scene.add(new THREE.AmbientLight(0x404040)); // Soft ambient light

            const material = new THREE.MeshLambertMaterial({ color: 0x0077ff }); // Default model color
            mesh = new THREE.Mesh(geometry, material);

            // Center the model
            geometry.computeBoundingBox();
            const box = geometry.boundingBox;
            const center = box.getCenter(new THREE.Vector3());
            mesh.position.sub(center);
            scene.add(mesh);

            // Adjust camera to fit the model
            const size = new THREE.Vector3();
            box.getSize(size);
            const maxDim = Math.max(size.x, size.y, size.z);
            camera.position.set(maxDim * 1.5, maxDim * 1.5, maxDim * 1.5);
            camera.lookAt(0, 0, 0);

            controls = new THREE.OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.dampingFactor = 0.1;
            controls.screenSpacePanning = false;
            controls.enableZoom = true;
            controls.enablePan = true;

            loadingMsg.style.display = 'none';
            animate();

            // Setup for object selection
            raycaster = new THREE.Raycaster();
            mouse = new THREE.Vector2();
            renderer.domElement.addEventListener('mousedown', onCanvasClick, false);
            renderer.domElement.addEventListener('touchstart', onCanvasClick, false);
        };
        reader.readAsArrayBuffer(file);
    }

    function onWindowResize() {
        if (camera && renderer && controls) {
            const canvas = document.getElementById('cadCanvas');
            const viewerDiv = canvas.parentElement;
            const width = viewerDiv.clientWidth;
            const height = viewerDiv.clientHeight;

            if (width > 0 && height > 0) {
                camera.aspect = width / height;
                camera.updateProjectionMatrix();
                renderer.setSize(width, height);
                controls.update();
            }
        }
    }

    function animate() {
        requestAnimationFrame(animate);
        if (controls) controls.update();
        if (renderer && scene && camera) {
            renderer.render(scene, camera);
        }
    }

    function removeObject() {
        if (mesh) {
            scene.remove(mesh);
            mesh = null;
            addMessageToLog('AI', "Object removed.");
            speakResponse("Object removed.");
            clearSelection();
        } else {
            addMessageToLog('AI', "No object to remove.");
            speakResponse("No object to remove.");
        }
    }

    function resetView() {
        if (mesh) mesh.rotation.set(0, 0, 0); // Reset rotation
        if (camera && mesh) {
            const box = new THREE.Box3().setFromObject(mesh);
            const size = new THREE.Vector3();
            box.getSize(size);
            const maxDim = Math.max(size.x, size.y, size.z);
            camera.position.set(maxDim * 1.5, maxDim * 1.5, maxDim * 1.5);
            camera.lookAt(0, 0, 0);
            controls.update();
            addMessageToLog('AI', "View reset.");
            speakResponse("View reset.");
        } else {
            addMessageToLog('AI', "No object to reset view for.");
            speakResponse("No object to reset view for.");
        }
    }

    function goBack() {
        editorPage.classList.remove('page-active');
        editorPage.classList.add('page-inactive');

        uploadPage.classList.remove('page-inactive');
        uploadPage.classList.add('page-active');

        stopVoiceAssist(); // Ensure voice assist is stopped when going back

        // Dispose of Three.js resources when navigating back
        if (scene) {
            scene.traverse(function (object) {
                if (object.isMesh) {
                    if (object.geometry) object.geometry.dispose();
                    if (object.material) {
                        if (Array.isArray(object.material)) {
                            object.material.forEach(material => material.dispose());
                        } else {
                            object.material.dispose();
                        }
                    }
                }
            });
            scene = null;
        }
        if (renderer) {
            renderer.dispose();
            renderer = null;
        }
        if (controls) {
            controls.dispose();
            controls = null;
        }
        window.removeEventListener('resize', onWindowResize, false);
        clearSelection(); // Clear any active selection
        if (renderer && renderer.domElement) {
            renderer.domElement.removeEventListener('mousedown', onCanvasClick, false);
            renderer.domElement.removeEventListener('touchstart', onCanvasClick, false);
        }
        uploadedFile = null; // Clear the uploaded file
        dropZone.style.borderColor = '#aaa'; // Reset drop zone style
        dropZone.textContent = 'Drag and Drop your .stl file here'; // Reset drop zone text
    }

    function showDesignInfo() {
        if (!mesh) {
            addMessageToLog('AI', "No design loaded.");
            speakResponse("No design loaded.");
            return;
        }
        const box = new THREE.Box3().setFromObject(mesh);
        const size = new THREE.Vector3();
        box.getSize(size);
        const info = `Width: ${size.x.toFixed(2)}\nHeight: ${size.y.toFixed(2)}\nDepth: ${size.z.toFixed(2)}`;
        addMessageToLog('AI', info.replace(/\n/g, ', ')); // Log to AI panel
        speakResponse(info); // Speak the info
    }

    /* Raycasting and Selection */
    function onCanvasClick(event) {
        event.preventDefault();

        const canvas = renderer.domElement;
        const rect = canvas.getBoundingClientRect();

        if (event.changedTouches) { // Handle touch events
            mouse.x = ((event.changedTouches[0].clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.changedTouches[0].clientY - rect.top) / rect.height) * 2 + 1;
        } else { // Handle mouse events
            mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
        }

        raycaster.setFromCamera(mouse, camera);

        const intersects = raycaster.intersectObjects(scene.children, true);

        if (intersects.length > 0) {
            const intersected = intersects[0].object;

            if (intersected === mesh) { // Only allow selection of the main loaded mesh
                if (selectedObject && selectedObject.material) {
                    // Restore original color of previously selected object
                    if (Array.isArray(selectedObject.material)) {
                        selectedObject.material.forEach(m => m.color.copy(originalMaterialColor));
                    } else {
                        selectedObject.material.color.copy(originalMaterialColor);
                    }
                }

                selectedObject = intersected;
                if (Array.isArray(selectedObject.material)) {
                    originalMaterialColor = selectedObject.material[0].color.clone();
                    selectedObject.material.forEach(m => m.color.set(0xffff00)); // Highlight in yellow
                } else {
                    originalMaterialColor = selectedObject.material.color.clone();
                    selectedObject.material.color.set(0xffff00); // Highlight in yellow
                }

                console.log("Object selected:", selectedObject.name || selectedObject.uuid);
                addMessageToLog('System', "Object selected.");
                speakResponse("Object selected.");
            } else {
                clearSelection(); // Clicked on something else, clear selection
            }
        } else {
            clearSelection(); // Clicked on empty space, clear selection
        }
        // Ensure render is called after selection change
        if (renderer && scene && camera) {
            renderer.render(scene, camera);
        }
    }

    function clearSelection() {
        if (selectedObject && originalMaterialColor) {
            if (Array.isArray(selectedObject.material)) {
                selectedObject.material.forEach(m => m.color.copy(originalMaterialColor));
            } else {
                selectedObject.material.color.copy(originalMaterialColor);
            }
            selectedObject = null;
            originalMaterialColor = null;
            console.log("Selection cleared.");
            addMessageToLog('System', "Selection cleared.");
        }
        if (renderer && scene && camera) {
            renderer.render(scene, camera);
        }
    }

    /* AI Interaction Panel Functions */
    function addMessageToLog(sender, message) {
        const p = document.createElement('p');
        p.textContent = `${sender}: ${message}`;
        p.classList.add(sender === 'User' ? 'user-message' : (sender === 'AI' ? 'ai-response' : 'system-message'));
        aiLog.appendChild(p);
        aiLog.scrollTop = aiLog.scrollHeight; // Scroll to bottom
    }

    // Handle text input for AI commands
    sendTextCommandBtn.addEventListener('click', () => {
        const command = textCommandInput.value.trim();
        if (command) {
            addMessageToLog('User', command);
            processAICommand(command); // Process the command via the backend
            textCommandInput.value = '';
        }
    });

    textCommandInput.addEventListener('keypress', (event) => {
        if (event.key === 'Enter') {
            sendTextCommandBtn.click();
        }
    });


    /* AI Voice Assist Functions */
    voiceAssistBtn.addEventListener('click', toggleVoiceAssist);

    function initializeSpeechRecognition() {
        if (!('webkitSpeechRecognition' in window)) {
            addMessageToLog('System', "Speech recognition not supported in this browser. Please use Google Chrome.");
            return null;
        }
        const newRecognition = new webkitSpeechRecognition();
        newRecognition.continuous = true; // Keep listening
        newRecognition.interimResults = false; // Only return final results
        newRecognition.lang = 'en-US';
        return newRecognition;
    }

    function initializeSpeechSynthesis() {
        if (!('speechSynthesis' in window)) {
            addMessageToLog('System', "Speech synthesis not supported in this browser.");
            return null;
        }
        return window.speechSynthesis;
    }

    function speakResponse(text) {
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }
        synth.cancel(); // Stop any ongoing speech

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'en-US';
        utterance.onend = () => {
            console.log('Speech synthesis ended');
            // Only restart recognition if voice assist is still active and synth is not speaking
            if (isVoiceAssistActive && recognition && !synth.speaking) {
                // *** NEW: Add a delay before restarting recognition ***
                setTimeout(() => {
                    addMessageToLog('System', "Listening...");
                    recognition.start();
                }, 1500); // 1.5 second delay
            }
        };
        utterance.onerror = (event) => {
            console.error('Speech synthesis error:', event);
            addMessageToLog('System', "Error speaking response.");
        };
        synth.speak(utterance);
    }

    function toggleVoiceAssist() {
        if (!mesh) {
            addMessageToLog('AI', "Please load an STL model first.");
            speakResponse("Please load an STL model first.");
            return;
        }

        if (!recognition) {
            recognition = initializeSpeechRecognition();
            if (!recognition) return;
        }
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }

        if (isVoiceAssistActive) {
            stopVoiceAssist();
            speakResponse("Voice assist stopped. Goodbye!");
        } else {
            isVoiceAssistActive = true;
            voiceAssistBtn.classList.add('active-voice-btn');
            voiceAssistBtn.innerHTML = 'âŒ Stop AI Voice'; // Updated button text
            aiInteractionPanel.classList.add('active'); // Show AI panel
            addMessageToLog('System', "Starting voice assist...");

            speakResponse("Hi, what can I help you with?");
        }

        recognition.onstart = function () {
            addMessageToLog('System', "Listening...");
            console.log('Speech recognition started');
        };

        recognition.onresult = function (event) {
            const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
            addMessageToLog('User', transcript); // Log user's spoken command
            addMessageToLog('System', "Processing voice command...");
            console.log('Speech recognized:', transcript);

            recognition.stop(); // Stop listening while processing
            processAICommand(transcript); // Process the command via the backend
        };

        recognition.onerror = function (event) {
            console.error('Speech recognition error:', event);
            let errorMessage = "An unknown speech recognition error occurred.";
            if (event.error === 'not-allowed') {
                errorMessage = "Microphone access denied. Please allow microphone access in your browser settings.";
            } else if (event.error === 'no-speech') {
                errorMessage = "No speech detected. Please try speaking louder or clearer.";
            } else if (event.error) {
                errorMessage = `Speech error: ${event.error}. Please try again.`;
            }
            addMessageToLog('System', errorMessage);
            speakResponse(errorMessage); // Speak the error message
            stopVoiceAssist(); // Stop voice assist on error
        };

        recognition.onend = function () {
            console.log('Speech recognition ended');
            // If voice assist is still active and synth is not speaking, restart recognition
            // The restart logic is now primarily handled within speakResponse.onend
            // This ensures a delay after AI finishes speaking before listening resumes.
        };
    }

    function stopVoiceAssist() {
        isVoiceAssistActive = false;
        if (recognition && typeof recognition.stop === 'function') {
            recognition.stop();
        }
        if (synth && typeof synth.cancel === 'function') {
            synth.cancel();
        }
        aiInteractionPanel.classList.remove('active'); // Hide AI panel
        voiceAssistBtn.classList.remove('active-voice-btn');
        voiceAssistBtn.innerHTML = 'ðŸ§  AI Voice Assist';
        addMessageToLog('System', "Voice assist stopped.");
    }

    // This function handles both voice and text commands
    async function processAICommand(command) {
        // Handle selection-related commands directly in frontend
        if (command.includes("select object")) {
            if (selectedObject) {
                speakResponse("An object is already selected. Click on the model to change selection or click outside to clear.");
            } else if (mesh) {
                speakResponse("Please click on the model to select it.");
            } else {
                speakResponse("No model loaded to select.");
            }
            return; // Exit after handling
        } else if (command.includes("clear selection")) {
            clearSelection();
            speakResponse("Selection cleared.");
            return; // Exit after handling
        }

        try {
            // Use the sendToAI function to communicate with your backend
            const aiReply = await sendToAI(command);

            console.log("AI replied:", aiReply);

            if (aiReply && typeof aiReply === 'object' && aiReply.action) {
                switch (aiReply.action) {
                    case 'rotate':
                        if (mesh && typeof aiReply.value === 'number') {
                            // Convert degrees to radians for Three.js rotation
                            mesh.rotation.y += THREE.MathUtils.degToRad(aiReply.value);
                            addMessageToLog('AI', `Model rotated by ${aiReply.value} degrees.`);
                            speakResponse(`Model rotated by ${aiReply.value} degrees.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't rotate the model. Please specify a valid degree value.");
                            speakResponse("Sorry, I couldn't rotate the model. Please specify a valid degree value.");
                        }
                        break;
                    case 'scale':
                        if (mesh && typeof aiReply.value === 'number' && aiReply.value > 0) {
                            mesh.scale.set(aiReply.value, aiReply.value, aiReply.value);
                            addMessageToLog('AI', `Model scaled by a factor of ${aiReply.value}.`);
                            speakResponse(`Model scaled by a factor of ${aiReply.value}.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't scale the model. Please specify a positive scale factor (e.g., 0.5, 2).");
                            speakResponse("Sorry, I couldn't scale the model. Please specify a positive scale factor.");
                        }
                        break;
                    case 'move':
                        if (mesh && typeof aiReply.value === 'object' && aiReply.value.x !== undefined && aiReply.value.y !== undefined && aiReply.value.z !== undefined) {
                            mesh.position.x += aiReply.value.x;
                            mesh.position.y += aiReply.value.y;
                            mesh.position.z += aiReply.value.z;
                            addMessageToLog('AI', `Model moved by X:${aiReply.value.x}, Y:${aiReply.value.y}, Z:${aiReply.value.z} units.`);
                            speakResponse(`Model moved by X:${aiReply.value.x}, Y:${aiReply.value.y}, Z:${aiReply.value.z} units.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't move the model. Please specify valid X, Y, and Z values (e.g., move by X 10, Y -5, Z 0).");
                            speakResponse("Sorry, I couldn't move the model. Please specify valid X, Y, and Z values.");
                        }
                        break;
                    case 'color':
                        if (mesh && typeof aiReply.value === 'string' && /^#([0-9A-F]{3}){1,2}$/i.test(aiReply.value)) {
                            if (Array.isArray(mesh.material)) {
                                mesh.material.forEach(m => m.color.set(aiReply.value));
                            } else {
                                mesh.material.color.set(aiReply.value);
                            }
                            addMessageToLog('AI', `Model color changed to ${aiReply.value}.`);
                            speakResponse(`Model color changed to ${aiReply.value}.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't change the color. Please provide a valid hexadecimal color code, like #FF0000 for red.");
                            speakResponse("Sorry, I couldn't change the color. Please provide a valid hexadecimal color code, like #FF0000 for red.");
                        }
                        break;
                    case 'conversational':
                        // Prefer 'value', fall back to 'message' for conversational responses
                        let responseText = aiReply.value || aiReply.message;
                        if (responseText) {
                            addMessageToLog('AI', responseText);
                            speakResponse(responseText);
                        } else {
                            addMessageToLog('AI', "I received a conversational response but it was empty.");
                            speakResponse("I received a conversational response but it was empty.");
                        }
                        break;
                    case 'error':
                        addMessageToLog('AI', `An AI error occurred: ${aiReply.value}. Please try again.`);
                        speakResponse("An error occurred with the AI. Please try again.");
                        console.error("AI returned an error action:", aiReply.value);
                        break;
                    default:
                        addMessageToLog('AI', "The AI sent an unrecognized command. Please try again.");
                        speakResponse("The AI sent an unrecognized command. Please try again.");
                        console.warn("AI sent unrecognized action:", aiReply.action);
                        break;
                }
            } else {
                // If aiReply is not a structured object or has no action, treat as direct conversational response
                addMessageToLog('AI', aiReply);
                speakResponse(aiReply);
            }
        } catch (error) {
            console.error("Error processing AI command:", error);
            addMessageToLog('AI', "I'm sorry, I encountered an error while processing your command. Please try again.");
            speakResponse("I'm sorry, I encountered an error. Please try again.");
        }
    }

    // Function to send commands to your OpenAI backend
    async function sendToAI(prompt) {
        sendTextCommandBtn.disabled = true;
        textCommandInput.disabled = true;
        addMessageToLog('System', 'AI is thinking...');

        const payload = {
            prompt: prompt // Send the user's prompt to your backend
        };

        try {
            const response = await fetch('https://mingyu.onrender.com/api/ai', { // Point to your Render backend
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`Backend error: ${errorData.message || response.statusText}`);
            }

            const result = await response.json();
            console.log("Raw AI response from backend:", result);

            // Assuming your backend directly returns the structured JSON or conversational message
            return result;

        } catch (error) {
            console.error("Error communicating with backend AI:", error);
            return { action: 'error', value: `Failed to communicate with AI: ${error.message}` };
        } finally {
            sendTextCommandBtn.disabled = false;
            textCommandInput.disabled = false;
            const lastLogMessage = aiLog.lastChild;
            if (lastLogMessage && lastLogMessage.textContent.includes('AI is thinking...')) {
                aiLog.removeChild(lastLogMessage);
            }
        }
    }
</script>
