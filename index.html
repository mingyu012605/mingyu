<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI VR CAD Editor</title>
    <!-- Using Inter font from Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <style>
        /* Global Styles */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            font-family: 'Inter', sans-serif; /* Changed font to Inter */
            background: #f0f2f5; /* Lighter, subtle background for overall app */
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }

        /* Header */
        header {
            background-color: #1a202c; /* Darker, more professional header */
            padding: 15px 25px;
            color: #e2e8f0; /* Lighter text for contrast */
            text-align: center;
            font-size: 2.2rem; /* Slightly smaller, more refined font size */
            font-weight: 700; /* Bolder font weight */
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            flex-shrink: 0;
            height: 70px; /* Slightly reduced height */
            box-sizing: border-box;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2); /* Subtle shadow for depth */
        }

        header svg {
            height: 35px; /* Slightly smaller icon */
            width: 35px;
            fill: #007bff; /* Accent color for the logo */
            transition: transform 0.3s ease; /* Smooth transition for hover effect */
        }

        header:hover svg {
            transform: rotate(5deg) scale(1.05); /* Slight rotation and scale on hover */
        }

        /* Page Container & Transitions */
        .page-container {
            display: flex;
            flex-direction: column;
            flex-grow: 1;
            width: 100%;
            position: relative;
        }

        .page {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            transition: opacity 0.6s ease-in-out, transform 0.6s ease-in-out; /* Smoother transitions */
            transform: translateX(0); /* Default position */
        }

        .page-active {
            opacity: 1;
            pointer-events: auto;
            z-index: 1;
        }

        .page-inactive {
            opacity: 0;
            pointer-events: none;
            z-index: 0;
            transform: translateX(-100%); /* Slide out to the left */
        }

        /* Upload Page */
        #uploadPage {
            background-color: #f0f2f5; /* Consistent with body background */
            color: #333;
            padding: 20px; /* Add some padding */
            box-sizing: border-box;
        }

        .upload-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 25px; /* Increased gap for better spacing */
            background: #ffffff;
            padding: 50px 60px; /* More generous padding */
            border-radius: 15px; /* More rounded corners */
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.15); /* Stronger, softer shadow */
            width: 90%; /* Responsive width */
            max-width: 500px; /* Max width for larger screens */
            text-align: center;
        }

        .upload-content h2 {
            color: #1a202c;
            margin-bottom: 15px; /* Adjusted margin */
            font-size: 2.2em; /* Slightly larger heading */
            font-weight: 700;
        }

        #dropZone {
            width: 100%; /* Full width within its container */
            height: 180px; /* Taller drop zone */
            border: 3px dashed #a0aec0; /* Thicker, slightly darker dashed border */
            border-radius: 10px;
            display: flex;
            justify-content: center;
            align-items: center;
            text-align: center;
            color: #4a5568; /* Darker text */
            cursor: pointer;
            transition: border-color 0.4s ease, background-color 0.4s ease, color 0.4s ease;
            font-size: 1.2em; /* Larger font size */
            background-color: #f7fafc; /* Slightly off-white background */
            font-weight: 600;
            position: relative; /* Needed for absolute positioning of fileInput */
            overflow: hidden; /* Hide overflow of fileInput */
        }

        #dropZone:hover {
            border-color: #007bff; /* Accent color on hover */
            background-color: #e6f0ff; /* Light blue background on hover */
            color: #0056b3;
        }

        #fileInput {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            opacity: 0; /* Make it transparent */
            cursor: pointer;
            z-index: 2; /* Ensure it's above the dropZone text */
        }

        .button-group {
            display: flex;
            gap: 20px; /* Increased gap between buttons */
            margin-top: 25px;
        }

        .button {
            padding: 14px 30px; /* Larger padding */
            border: none;
            border-radius: 8px; /* More rounded buttons */
            cursor: pointer;
            font-size: 1.1em; /* Slightly larger font */
            font-weight: 600; /* Bolder text */
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Subtle button shadow */
        }

        .button.primary {
            background-color: #007bff;
            color: white;
        }

        .button.primary:hover {
            background-color: #0056b3;
            transform: translateY(-3px); /* More pronounced lift */
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2);
        }

        .button.secondary {
            background-color: #6c757d;
            color: white;
        }

        .button.secondary:hover {
            background-color: #5a6268;
            transform: translateY(-3px);
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2);
        }

        #loadingMsg {
            display: none;
            margin-top: 25px; /* Adjusted margin */
            color: #007bff;
            font-size: 1.15em; /* Slightly larger font */
            font-weight: 600;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.05); /* Very subtle text shadow */
        }

        /* Editor Page */
        #editorPage {
            background-color: #2d3748; /* Darker, more immersive background for editor */
            flex-direction: row;
            justify-content: flex-start;
            align-items: stretch;
            padding: 0;
            box-sizing: border-box;
        }

        .sidebar {
            width: 300px; /* Slightly wider sidebar */
            background-color: #1a202c; /* Darker sidebar background */
            padding: 25px; /* More padding */
            display: flex;
            flex-direction: column;
            border-right: 1px solid #2d3748; /* Darker border */
            box-shadow: 4px 0 10px rgba(0, 0, 0, 0.3); /* Stronger shadow for sidebar */
            flex-shrink: 0;
            overflow-y: auto;
            color: #e2e8f0; /* Lighter text for sidebar */
        }

        .sidebar h2 {
            color: #ffffff; /* White heading */
            margin-bottom: 25px;
            font-size: 1.9em; /* Slightly larger heading */
            border-bottom: 2px solid #007bff; /* Accent color border */
            padding-bottom: 12px;
            font-weight: 700;
        }

        .editor-controls {
            display: flex;
            flex-direction: column;
            gap: 18px; /* Increased gap */
            margin-bottom: 35px;
        }

        .control-button {
            width: 100%;
            padding: 14px; /* Larger padding */
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 8px; /* More rounded buttons */
            cursor: pointer;
            font-size: 1.05em; /* Slightly larger font */
            font-weight: 600;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            box-shadow: 0 3px 6px rgba(0, 0, 0, 0.15);
        }

        .control-button:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0, 0, 0, 0.25);
        }

        .control-button svg {
            fill: white;
            height: 22px; /* Slightly larger icons */
            width: 22px;
        }

        #cadViewer {
            flex-grow: 1;
            background-color: #2d3748; /* Consistent with editor background */
            position: relative;
        }

        #cadCanvas {
            display: block;
            width: 100%;
            height: 100%;
        }

        /* AI Interaction Panel */
        #aiInteractionPanel {
            background-color: #1a202c; /* Same as sidebar background */
            border-top: 1px solid #2d3748; /* Darker border */
            padding: 20px;
            display: flex;
            flex-direction: column;
            gap: 15px; /* Increased gap */
            flex-shrink: 0;
            height: auto;
            max-height: 45%; /* Slightly more height for chat */
            overflow: hidden;
            transition: all 0.4s ease-in-out; /* Smoother transition */
            position: absolute;
            bottom: 0;
            width: 100%;
            left: 0;
            box-sizing: border-box;
            transform: translateY(100%);
            opacity: 0;
            box-shadow: 0 -4px 10px rgba(0, 0, 0, 0.3); /* Shadow for the panel */
        }

        #aiInteractionPanel.active {
            transform: translateY(0);
            opacity: 1;
            max-height: 80%; /* Can expand further if needed */
        }


        #aiLog {
            flex-grow: 1;
            background-color: #2d3748; /* Darker background for log */
            border-radius: 10px; /* Rounded corners for log */
            padding: 15px;
            color: #e2e8f0; /* Light text for readability */
            overflow-y: auto;
            height: 180px; /* Increased default height */
            flex-shrink: 1;
            line-height: 1.5; /* Better line spacing */
        }

        #aiLog p {
            margin: 7px 0; /* Adjusted margin */
            padding: 5px 10px;
            border-radius: 6px;
        }

        .user-message {
            background-color: #007bff; /* Accent color for user messages */
            color: white;
            text-align: right;
            align-self: flex-end; /* Align to the right */
            max-width: 80%; /* Limit width */
            margin-left: auto; /* Push to right */
        }

        .ai-response {
            background-color: #4a5568; /* Darker grey for AI responses */
            color: #e2e8f0;
            text-align: left;
            align-self: flex-start; /* Align to the left */
            max-width: 80%;
            margin-right: auto;
        }

        .system-message {
            background-color: #2d3748; /* Background for system messages */
            color: #cbd5e0; /* Lighter grey for system messages */
            text-align: center;
            font-style: italic;
            border-bottom: 1px dashed #4a5568; /* Subtle separator */
            padding-bottom: 10px;
            margin-bottom: 10px;
        }

        .ai-input-group {
            display: flex;
            gap: 10px;
            flex-shrink: 0;
        }

        #textCommandInput {
            flex-grow: 1;
            padding: 12px; /* Larger padding */
            border: 1px solid #4a5568; /* Darker border */
            border-radius: 8px; /* Rounded corners */
            background-color: #2d3748; /* Dark background */
            color: #e2e8f0; /* Light text */
            font-size: 1em;
            outline: none; /* Remove default outline */
            box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.3); /* Inner shadow */
        }

        #textCommandInput::placeholder {
            color: #a0aec0; /* Lighter placeholder text */
        }

        #textCommandInput:focus {
            border-color: #007bff; /* Accent color on focus */
            box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.3), 0 0 0 2px rgba(0, 123, 255, 0.3); /* Focus ring */
        }

        #sendTextCommandBtn {
            padding: 12px 20px; /* Consistent padding */
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            box-shadow: 0 3px 6px rgba(0, 0, 0, 0.15);
        }

        #sendTextCommandBtn:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0, 0, 0, 0.25);
        }

        #voiceAssistBtn {
            background-color: #4a5568; /* Darker grey for voice button */
            border: none;
            border-radius: 10px; /* More rounded */
            padding: 18px 25px; /* Larger padding */
            font-size: 1.15em;
            font-weight: 700;
            color: white;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
            position: absolute;
            bottom: 30px; /* More space from bottom */
            right: 30px; /* More space from right */
            display: flex;
            align-items: center;
            gap: 12px;
            z-index: 10;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.25); /* Stronger shadow */
        }

        #voiceAssistBtn:hover {
            background-color: #2d3748; /* Even darker on hover */
            transform: translateY(-4px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.35);
        }

        #voiceAssistBtn.active-voice-btn {
            background-color: #e53e3e; /* Red for active state */
            box-shadow: 0 5px 15px rgba(229, 62, 62, 0.4); /* Red glow */
        }

        #voiceAssistBtn.active-voice-btn:hover {
            background-color: #c53030;
            transform: translateY(-4px);
            box-shadow: 0 8px 20px rgba(229, 62, 62, 0.5);
        }
    </style>
    <!-- Import Map for ES Modules -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/"
            }
        }
    </script>
</head>
<body>
    <header>
        <!-- New Innovative Logo SVG -->
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
            <path d="M12 1L2 6v12l10 5 10-5V6L12 1zm0 2.31L18.47 6 12 9.31 5.53 6 12 3.31zM4 7.69l6 3.15v6.52L4 13.84V7.69zm8 11.01L6.47 16 12 12.69l5.53 3.31L12 18.7zM20 13.84l-6 3.15V10.84l6-3.15v6.15z"/>
            <circle cx="12" cy="12" r="2" fill="#007bff"/>
            <path d="M12 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z" fill="#fff"/>
        </svg>
        AI VR CAD Editor
    </header>

    <div class="page-container">
        <section id="uploadPage" class="page page-active">
            <div class="upload-content">
                <h2>Upload your 3D Model</h2>
                <!-- Removed onclick from dropZone; fileInput will handle clicks directly -->
                <div id="dropZone">
                    Drag and Drop your .gltf or .glb file(s) here
                    <input type="file" id="fileInput" accept=".gltf,.glb" />
                </div>
                <button class="button primary" id="loadEditorButton">Load Model & Go to Editor</button>
                <p id="loadingMsg">Loading model, please wait...</p>
            </div>
        </section>

        <section id="editorPage" class="page page-inactive">
            <aside class="sidebar">
                <h2>Controls</h2>
                <div class="editor-controls">
                    <button class="control-button" onclick="window.removeObject()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M6 19c0 1.1.9 2 2 2h8c1.1 0 2-.9 2-2V7H6v12zm2.46-7.12l1.41-1.41L12 12.59l2.12-2.12 1.41 1.41L13.41 14l2.12 2.12-1.41 1.41L12 15.41l-2.12 2.12-1.41-1.41L10.59 14l-2.13-2.12zM15.5 4l-1-1h-5l-1 1H5v2h14V4h-3.5z"/></svg>
                        Remove Object
                    </button>
                    <button class="control-button" onclick="window.resetView()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M12 4C7.31 4 3.07 5.9 0 8.98L12 21 24 8.98C20.93 5.9 16.69 4 12 4zm0 2.98c2.18 0 4.2.82 5.74 2.37L12 18.06 6.26 9.35C7.8 7.8 9.82 6.98 12 6.98z"/></svg>
                        Reset View
                    </button>
                    <button class="control-button" onclick="window.showDesignInfo()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M11 7h2v2h-2zm0 4h2v6h-2zm1-9C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8z"/></svg>
                        Design Info
                    </button>
                    <button class="control-button" onclick="window.goBack()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M12 2c5.52 0 10 4.48 10 10s-4.48 10-10 10S2 17.52 2 12 6.48 2 12 2zm0 18c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8zm-1-13v4H7.5L12 16.5 16.5 12H13V7z"/></svg>
                        Back to Upload
                    </button>
                </div>

                <h2>AI Chat Log</h2>
                <div id="aiLog">
                    <p class="system-message">System: AI Chat Log Initialized.</p>
                </div>
                <div class="ai-input-group">
                    <input type="text" id="textCommandInput" placeholder="Type AI command or question..." />
                    <button id="sendTextCommandBtn">Send</button>
                </div>
            </aside>

            <main id="cadViewer">
                <canvas id="cadCanvas"></canvas>
            </main>
            <button id="voiceAssistBtn">🧠 AI Voice Assist</button>
            <div id="aiInteractionPanel"></div>
        </section>
    </div>

<script type="module">
    // Import Three.js and its modules
    import * as THREE from 'three';
    import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
    import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
    import { VRButton } from 'three/addons/webxr/VRButton.js';

    // Global map to store dropped files by their relative path (e.g., "scene.bin", "textures/image.png")
    const droppedFileBlobs = new Map();

    let uploadedFile = null, scene, camera, renderer, mesh, controls;
    let recognition;
    let synth;
    let isVoiceAssistActive = false;
    let raycaster;
    let mouse;
    let selectedObject = null; // This will hold the currently selected THREE.Mesh part
    const originalMaterials = new Map(); // Map to store original materials by object UUID

    // Get references to HTML elements
    const fileInput = document.getElementById('fileInput');
    const dropZone = document.getElementById('dropZone');
    const loadingMsg = document.getElementById('loadingMsg');
    const uploadPage = document.getElementById('uploadPage');
    const editorPage = document.getElementById('editorPage');
    const voiceAssistBtn = document.getElementById('voiceAssistBtn');
    const aiInteractionPanel = document.getElementById('aiInteractionPanel');
    const aiLog = document.getElementById('aiLog');
    const textCommandInput = document.getElementById('textCommandInput');
    const sendTextCommandBtn = document.getElementById('sendTextCommandBtn');
    const cadCanvas = document.getElementById('cadCanvas'); // Reference to the canvas element
    const loadEditorButton = document.getElementById('loadEditorButton'); // Reference to the new button ID

    // --- File Input and Page Navigation ---
    // Removed the click listener from dropZone as fileInput will handle clicks directly
    dropZone.addEventListener('dragover', e => {
        e.preventDefault();
        dropZone.textContent = 'Release to drop your .gltf or .glb file(s)';
        dropZone.style.borderColor = '#007bff';
    });
    dropZone.addEventListener('dragleave', () => {
        dropZone.textContent = 'Drag and Drop your .gltf or .glb file(s) here';
        dropZone.style.borderColor = '#a0aec0'; // Reset to original color
    });
    dropZone.addEventListener('drop', async e => {
        e.preventDefault();
        dropZone.textContent = 'Processing files...';
        dropZone.style.borderColor = '#a0aec0'; // Reset to original color
        loadingMsg.textContent = 'Processing dropped files...';
        loadingMsg.style.color = '#007bff';
        loadingMsg.style.display = 'block';

        droppedFileBlobs.clear(); // Clear previous files
        let mainModelFile = null;

        console.log("[Drop Handler] Drop event detected. Items:", e.dataTransfer.items);
        console.log("[Drop Handler] Files:", e.dataTransfer.files);

        // Function to recursively read directory entries
        async function readDroppedFiles(entry, path) {
            if (entry.isFile) {
                const file = await new Promise(resolve => entry.file(resolve));
                const fullPath = path ? `${path}/${file.name}` : file.name;
                droppedFileBlobs.set(fullPath, file);
                console.log(`[Drop Handler] Stored file: ${fullPath}, Type: ${file.type}, Size: ${file.size} bytes`); // Debugging
                if (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb')) {
                    mainModelFile = file;
                }
            } else if (entry.isDirectory) {
                const directoryReader = entry.createReader();
                const entries = await new Promise(resolve => directoryReader.readEntries(resolve));
                console.log(`[Drop Handler] Reading directory: ${path ? `${path}/${entry.name}` : entry.name}, Entries found: ${entries.length}`);
                for (const subEntry of entries) {
                    await readDroppedFiles(subEntry, path ? `${path}/${entry.name}` : entry.name);
                }
            }
        }

        // Check if DataTransferItem.webkitGetAsEntry is available (for folder drops)
        if (e.dataTransfer.items && e.dataTransfer.items.length > 0 && e.dataTransfer.items[0].webkitGetAsEntry) {
            console.log("[Drop Handler] Using webkitGetAsEntry for folder drop detection.");
            for (let i = 0; i < e.dataTransfer.items.length; i++) {
                const item = e.dataTransfer.items[i];
                const entry = item.webkitGetAsEntry();
                if (entry) {
                    await readDroppedFiles(entry, ''); // Start recursive read from root
                }
            }
        } else {
            console.log("[Drop Handler] Falling back to flat file drop (webkitGetAsEntry not available or not a folder drop).");
            // Fallback for browsers that's don't support webkitGetAsEntry or if only files are dropped
            for (let i = 0; i < e.dataTransfer.files.length; i++) {
                const file = e.dataTransfer.files[i];
                droppedFileBlobs.set(file.name, file);
                console.log(`[Drop Handler] Stored file (flat): ${file.name}, Type: ${file.type}, Size: ${file.size} bytes`); // Debugging
                if (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb')) {
                    mainModelFile = file;
                }
            }
        }

        if (mainModelFile) {
            uploadedFile = mainModelFile; // Set the main model file
            console.log("[Drop Handler] Identified main model file:", uploadedFile.name);
            validateFile(uploadedFile); // Validate and proceed
            console.log("[Drop Handler] All dropped files (keys in map):", Array.from(droppedFileBlobs.keys()));
        } else {
            loadingMsg.textContent = '❌ No .gltf or .glb file found among dropped items!';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            uploadedFile = null;
            console.error("[Drop Handler] No GLTF/GLB file found in dropped items.");
        }
        console.log("[Drop Handler] uploadedFile after drop processing:", uploadedFile ? uploadedFile.name : "null");
    });

    fileInput.addEventListener('change', () => {
        console.log("[File Input] Change event detected. Files:", fileInput.files);
        // For file input, we only get one file, so it's simpler
        if (fileInput.files.length > 0) {
            loadingMsg.textContent = 'Processing selected file...';
            loadingMsg.style.color = '#007bff';
            loadingMsg.style.display = 'block';

            droppedFileBlobs.clear();
            const file = fileInput.files[0];
            droppedFileBlobs.set(file.name, file);
            uploadedFile = file;
            console.log("[File Input] Selected file:", uploadedFile.name, `Type: ${uploadedFile.type}, Size: ${uploadedFile.size} bytes`);
            validateFile(uploadedFile);
            console.log("[File Input] Dropped file (keys in map):", Array.from(droppedFileBlobs.keys()));
        } else {
            console.log("[File Input] No file selected via input.");
            uploadedFile = null;
            loadingMsg.textContent = 'No file selected. Please choose a .gltf or .glb file.';
            loadingMsg.style.color = 'orange';
            loadingMsg.style.display = 'block';
        }
        console.log("[File Input] uploadedFile after change processing:", uploadedFile ? uploadedFile.name : "null");
    });

    // Attach event listener for the "Load Model & Go to Editor" button
    loadEditorButton.addEventListener('click', goToEditor); // Correctly attach event listener

    function validateFile(file) {
        console.log("[Validation] Validating file:", file ? file.name : "null");
        if (file && (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb'))) {
            console.log("[Validation] File is a valid GLTF/GLB.");
            loadingMsg.textContent = `File selected: ${file.name}. Click 'Load Model & Go to Editor' or drop more files if needed.`;
            loadingMsg.style.color = '#007bff';
            loadingMsg.style.display = 'block';
            return true;
        } else {
            console.error("[Validation] Unsupported file type detected for:", file ? file.name : "null");
            loadingMsg.textContent = '❌ Unsupported file type! Please upload a .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            uploadedFile = null; // Ensure uploadedFile is null if validation fails
            return false;
        }
    }

    // Helper function to dispose Three.js resources
    function disposeSceneResources() {
        console.log("[Dispose] Disposing Three.js resources...");
        if (scene) {
            scene.traverse(function (object) {
                if (object.isMesh) {
                    if (object.geometry) object.geometry.dispose();
                    if (object.material) {
                        if (Array.isArray(object.material)) {
                            object.material.forEach(material => material.dispose());
                        } else {
                            object.material.dispose();
                        }
                    }
                }
            });
            scene = null; // Ensure scene is nulled out
        }
        if (renderer) {
            renderer.setAnimationLoop(null); // Stop animation loop
            renderer.dispose();
            renderer = null; // Ensure renderer is nulled out
        }
        if (controls) {
            controls.dispose();
            controls = null; // Ensure controls are nulled out
        }
        // Remove event listeners from the canvas to prevent memory leaks
        if (cadCanvas) {
            cadCanvas.removeEventListener('mousedown', onCanvasClick, false);
            cadCanvas.removeEventListener('touchstart', onCanvasClick, false);
        }
        console.log("[Dispose] Resources disposed.");
    }


    function goToEditor() {
        console.log("[goToEditor] Attempting to go to editor.");
        console.log("[goToEditor] Current uploadedFile:", uploadedFile ? uploadedFile.name : "null");
        if (!uploadedFile) {
            addMessageToLog('System', "Please upload a valid .gltf or .glb file before continuing.");
            loadingMsg.textContent = 'Please upload a valid .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            console.warn("[goToEditor] No uploaded file found.");
            return;
        }

        uploadPage.classList.remove('page-active');
        uploadPage.classList.add('page-inactive');

        editorPage.classList.remove('page-inactive');
        editorPage.classList.add('page-active');

        loadingMsg.textContent = `Loading model: ${uploadedFile.name}...`;
        loadingMsg.style.color = '#007bff';
        loadingMsg.style.display = 'block';
        console.log(`[goToEditor] Transitioning to editor. Preparing to load model: ${uploadedFile.name}`);
        console.log(`[goToEditor] Current droppedFileBlobs keys:`, Array.from(droppedFileBlobs.keys()));


        // Dispose existing resources before initializing a new scene
        disposeSceneResources();
        // Re-initialize the scene every time we go to editor to ensure a clean state
        initScene();

        loadModel(uploadedFile); // Load model after transition
    }

    function goBack() {
        console.log("[Navigation] Going back to upload page.");
        editorPage.classList.remove('page-active');
        editorPage.classList.add('page-inactive');

        uploadPage.classList.remove('page-inactive');
        uploadPage.classList.add('page-active');

        stopVoiceAssist(); // Ensure voice assist is stopped when going back

        // Dispose of Three.js resources when navigating back
        disposeSceneResources(); // Call the helper function

        uploadedFile = null; // Clear the uploaded file
        droppedFileBlobs.clear(); // Clear the map of dropped files
        originalMaterials.clear(); // Clear original materials map
        selectedObject = null; // Clear selected object

        dropZone.style.borderColor = '#a0aec0'; // Reset drop zone style
        dropZone.textContent = 'Drag and Drop your .gltf or .glb file(s) here'; // Reset drop zone text
        loadingMsg.style.display = 'none'; // Hide loading message
        loadingMsg.style.color = ''; // Reset color
        loadingMsg.textContent = 'Loading model, please wait...'; // Reset default message

        console.log("[Navigation] Returned to upload page. State reset.");
    }
    // Make goBack globally accessible
    window.goBack = goBack;

    // --- Three.js Scene Setup and Model Loading ---
    function initScene() {
        console.log("[initScene] Initializing Three.js scene...");
        scene = new THREE.Scene();
        scene.background = new THREE.Color(0x222222); // Dark background

        const viewerDiv = cadCanvas.parentElement;
        const width = viewerDiv.clientWidth;
        const height = viewerDiv.clientHeight;

        camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
        camera.position.set(0, 0, 50); // Initial camera position

        renderer = new THREE.WebGLRenderer({ canvas: cadCanvas, antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(width, height);
        renderer.xr.enabled = true; // Enable WebXR for VR

        // OrbitControls is now imported as a module
        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.25;

        // Lighting
        const ambientLight = new THREE.AmbientLight(0x404040); // Soft white light
        scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
        directionalLight.position.set(1, 1, 1).normalize();
        scene.add(directionalLight);

        // VR Button is now imported as a module
        // document.body.appendChild(VRButton.createButton(renderer)); // Keep commented unless VR is explicitly requested

        // Raycasting for selection
        raycaster = new THREE.Raycaster();
        mouse = new THREE.Vector2();

        // Attach event listeners for selection after renderer is set up
        renderer.domElement.addEventListener('mousedown', onCanvasClick, false);
        renderer.domElement.addEventListener('touchstart', onCanvasClick, false);

        window.addEventListener('resize', onWindowResize, false); // Re-add resize listener

        animate(); // Start the animation loop
        console.log("[initScene] Three.js scene initialized.");
    }

    function animate() {
        // Use renderer.setAnimationLoop for WebXR compatibility
        if (renderer) { // Ensure renderer exists before setting animation loop
            renderer.setAnimationLoop(() => {
                controls.update();
                renderer.render(scene, camera);
            });
        }
    }

    function loadModel(file) {
        console.log(`[loadModel] Attempting to load file: ${file.name}`);
        loadingMsg.textContent = `Loading model: ${file.name}...`;
        loadingMsg.style.color = '#007bff';
        loadingMsg.style.display = 'block';

        const loader = new GLTFLoader();

        let loadTimeout = setTimeout(() => {
            console.error(`[loadModel] Model loading timed out after 30 seconds for ${file.name}.`);
            loadingMsg.textContent = `Error: Model loading timed out for ${file.name}. Please check console for details. Ensure all associated files were dropped.`;
            loadingMsg.style.color = 'red';
            speakResponse(`Model loading timed out for ${file.name}. Please check console for details.`);
            // Optionally, you might want to stop the loader or reset the state here
        }, 30000); // 30-second timeout

        loader.manager.setURLModifier((url, path) => {
            console.log(`[URLModifier] Requested URL: "${url}", Base Path: "${path}"`);

            // 1. Try to get a clean relative path from the full URL
            let resolvedPath = url;
            try {
                const urlObj = new URL(url);
                resolvedPath = urlObj.pathname.substring(1); // Remove leading slash
                // Check if there's a 'filename' query parameter, which might be used by some loaders
                const filenameParam = urlObj.searchParams.get('filename');
                if (filenameParam) {
                    resolvedPath = filenameParam;
                }
            } catch (e) {
                // If URL constructor fails, assume it's already a relative path or filename
                resolvedPath = url;
            }

            // Normalize path separators for consistency (e.g., Windows vs. Unix paths)
            resolvedPath = resolvedPath.replace(/\\/g, '/');
            console.log(`[URLModifier] Normalized resolvedPath: "${resolvedPath}`);

            // 2. Check if the exact resolvedPath exists in our dropped files
            if (droppedFileBlobs.has(resolvedPath)) {
                const blob = droppedFileBlobs.get(resolvedPath);
                const blobUrl = URL.createObjectURL(blob);
                console.log(`[URLModifier] Found "${resolvedPath}" (exact match), creating Blob URL: ${blobUrl}`);
                return blobUrl;
            }

            // 3. If not found by full path, try just the filename (common for textures in GLTF)
            const fileNameOnly = resolvedPath.substring(resolvedPath.lastIndexOf('/') + 1);
            if (droppedFileBlobs.has(fileNameOnly)) {
                const blob = droppedFileBlobs.get(fileNameOnly);
                const blobUrl = URL.createObjectURL(blob);
                console.log(`[URLModifier] Found "${fileNameOnly}" (filename only match), creating Blob URL: ${blobUrl}`);
                return blobUrl;
            }

            // 4. Try matching the 'path' argument provided by GLTFLoader (it's often the base path)
            // Combine 'path' with fileNameOnly if 'path' is provided and not empty
            if (path && path !== '') {
                // Ensure path ends with a slash for correct concatenation
                const normalizedPath = path.endsWith('/') ? path : `${path}/`;
                const combinedPath = `${normalizedPath}${fileNameOnly}`;
                if (droppedFileBlobs.has(combinedPath)) {
                    const blob = droppedFileBlobs.get(combinedPath);
                    const blobUrl = URL.createObjectURL(blob);
                    console.log(`[URLModifier] Found "${combinedPath}" (combined path match), creating Blob URL: ${blobUrl}`);
                    return blobUrl;
                }
            }

            console.warn(`[URLModifier] GLTFLoader could not find referenced file: "${url}" (tried "${resolvedPath}", "${fileNameOnly}", and potentially combined paths). Falling back to original URL.`);
            return url; // Fallback to original URL
        });

        if (file.name.toLowerCase().endsWith('.glb')) {
            console.log(`[loadModel] Handling .glb file: ${file.name}`);
            const reader = new FileReader();
            reader.onload = (event) => {
                clearTimeout(loadTimeout); // Clear timeout on successful read
                console.log(`[FileReader] .glb file read successfully.`);
                const contents = event.target.result;
                loader.parse(contents, '', (gltf) => {
                    console.log(`[GLTFLoader] .glb parsing successful.`);
                    console.log(`[GLTFLoader] gltf.scene object:`, gltf.scene);
                    console.log(`[GLTFLoader] gltf.scene children count:`, gltf.scene ? gltf.scene.children.length : 0);

                    // Remove existing model if any
                    if (mesh) {
                        scene.remove(mesh);
                        mesh.traverse(obj => {
                            if (obj.isMesh) {
                                if (obj.geometry) obj.geometry.dispose();
                                if (obj.material) {
                                    if (Array.isArray(obj.material)) {
                                        obj.material.forEach(m => m.dispose());
                                    } else {
                                        m.dispose();
                                    }
                                }
                            }
                        });
                    }
                    clearSelection(); // Clear any previous selection

                    if (gltf.scene && gltf.scene.children.length > 0) {
                        mesh = gltf.scene; // The glTF scene is the main container for all objects
                        scene.add(mesh);

                        // Center and scale the model
                        const bbox = new THREE.Box3().setFromObject(mesh);
                        const center = bbox.getCenter(new THREE.Vector3());
                        mesh.position.sub(center); // Center the model's group

                        const size = bbox.getSize(new THREE.Vector3());
                        const maxDim = Math.max(size.x, size.y, size.z);
                        const desiredMaxDim = 40; // Target size for the model in the scene
                        const scaleFactor = desiredMaxDim / maxDim;
                        mesh.scale.set(scaleFactor, scaleFactor, scaleFactor);

                        // Adjust camera to fit the new model
                        const newBbox = new THREE.Box3().setFromObject(mesh); // Get bbox after scaling
                        const newSize = newBbox.getSize(new THREE.Vector3());
                        const newMaxDim = Math.max(newSize.x, newSize.y, newSize.z);
                        camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
                        camera.lookAt(0, 0, 0);
                        controls.update(); // Update controls after camera change

                        loadingMsg.style.display = 'none';
                        addMessageToLog('System', `Model '${file.name}' loaded successfully.`);
                        speakResponse(`Model loaded successfully.`);
                        console.log(`[loadModel] Model '${file.name}' successfully added to scene.`);
                    } else {
                        console.error(`[loadModel] GLB model '${file.name}' parsed successfully but contains no visible scene or objects.`);
                        loadingMsg.textContent = `Error: GLB model '${file.name}' loaded but appears empty or invalid.`;
                        loadingMsg.style.color = 'red';
                        speakResponse(`GLB model loaded but appears empty or invalid.`);
                        mesh = null; // Ensure mesh is null if the scene is empty
                    }

                }, (error) => {
                    clearTimeout(loadTimeout); // Clear timeout on error
                    console.error('[GLTFLoader] Error parsing GLB model:', error);
                    loadingMsg.textContent = 'Error parsing GLB model. Check console for details.';
                    loadingMsg.style.color = 'red';
                    speakResponse('Error parsing GLB model.');
                });
            };
            reader.onerror = (error) => {
                clearTimeout(loadTimeout); // Clear timeout on error
                console.error('[FileReader] Error reading GLB file:', error);
                loadingMsg.textContent = 'Error reading GLB file. Check console for details.';
                loadingMsg.style.color = 'red';
                speakResponse('Error reading GLB file.');
            };
            reader.readAsArrayBuffer(file);
        } else if (file.name.toLowerCase().endsWith('.gltf')) {
            console.log(`[loadModel] Handling .gltf file: ${file.name}`);
            const blobUrl = URL.createObjectURL(file);
            console.log(`[loadModel] Created Blob URL for main GLTF file: ${blobUrl}`);

            loader.load(blobUrl, (gltf) => {
                clearTimeout(loadTimeout); // Clear timeout on successful load
                console.log(`[GLTFLoader] .gltf loading successful.`);
                console.log(`[GLTFLoader] gltf.scene object:`, gltf.scene);
                console.log(`[GLTFLoader] gltf.scene children count:`, gltf.scene ? gltf.scene.children.length : 0);

                // Remove existing model if any
                if (mesh) {
                    scene.remove(mesh);
                    mesh.traverse(obj => {
                        if (obj.isMesh) {
                            if (obj.geometry) obj.geometry.dispose();
                            if (obj.material) {
                                if (Array.isArray(obj.material)) {
                                    obj.material.forEach(m => m.dispose());
                                } else {
                                    m.dispose();
                                }
                            }
                        }
                    });
                }
                clearSelection(); // Clear any previous selection

                if (gltf.scene && gltf.scene.children.length > 0) {
                    mesh = gltf.scene; // The glTF scene is the main container for all objects
                    scene.add(mesh);

                    // Center and scale the model
                    const bbox = new THREE.Box3().setFromObject(mesh);
                    const center = bbox.getCenter(new THREE.Vector3());
                    mesh.position.sub(center); // Center the model's group

                    const size = bbox.getSize(new THREE.Vector3());
                    const maxDim = Math.max(size.x, size.y, size.z);
                    const desiredMaxDim = 40; // Target size for the model in the scene
                    const scaleFactor = desiredMaxDim / maxDim;
                    mesh.scale.set(scaleFactor, scaleFactor, scaleFactor);

                    // Adjust camera to fit the new model
                    const newBbox = new THREE.Box3().setFromObject(mesh); // Get bbox after scaling
                    const newSize = newBbox.getSize(new THREE.Vector3());
                    const newMaxDim = Math.max(newSize.x, newSize.y, newSize.z);
                    camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
                    camera.lookAt(0, 0, 0);
                    controls.update(); // Update controls after camera change

                    loadingMsg.style.display = 'none';
                    addMessageToLog('System', `Model '${file.name}' loaded successfully.`);
                    speakResponse(`Model loaded successfully.`);
                    console.log(`[loadModel] Model '${file.name}' successfully added to scene.`);
                } else {
                    console.error(`[loadModel] GLTF model '${file.name}' loaded but contains no visible scene or objects.`);
                    loadingMsg.textContent = `Error: GLTF model '${file.name}' loaded but appears empty or invalid. Ensure all associated files (.bin, textures) are dropped together.`;
                    loadingMsg.style.color = 'red';
                    speakResponse(`GLTF model loaded but appears empty or invalid. Ensure all associated files are dropped together.`);
                    mesh = null; // Ensure mesh is null if the scene is empty
                }

                URL.revokeObjectURL(blobUrl); // Clean up the Blob URL

            }, (xhr) => {
                // Progress during loading
                console.log(`[GLTFLoader] Progress for ${file.name}: ${Math.round(xhr.loaded / xhr.total * 100)}%`);
                loadingMsg.textContent = `Loading ${file.name}: ${Math.round(xhr.loaded / xhr.total * 100)}%`;
            }, (error) => {
                clearTimeout(loadTimeout); // Clear timeout on error
                console.error('[GLTFLoader] Error loading GLTF model:', error);
                loadingMsg.textContent = 'Error loading GLTF model. Ensure all associated files (.bin, textures) are dropped together.';
                loadingMsg.style.color = 'red';
                speakResponse('Error loading GLTF model. Please ensure all associated files are dropped together.');
                URL.revokeObjectURL(blobUrl); // Clean up the Blob URL on error
            });
        } else {
            // This case should ideally be caught by validateFile, but as a fallback
            loadingMsg.textContent = '❌ Unsupported file type! Please upload a .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            speakResponse('Unsupported file type.');
        }
    }

    window.addEventListener('resize', onWindowResize, false);

    function onWindowResize() {
        const viewerDiv = cadCanvas.parentElement;
        const width = viewerDiv.clientWidth;
        const height = viewerDiv.clientHeight;

        if (width > 0 && height > 0) {
            camera.aspect = width / height;
            camera.updateProjectionMatrix();
            renderer.setSize(width, height);
            controls.update();
        }
    }

    // Initialize scene when the window loads
    window.onload = () => {
        initScene();
        initializeSpeechSynthesis();
    };

    // --- CAD Editor Functions ---
    // Note: removeObject, resetView, showDesignInfo are updated to handle selectedObject or mesh
    function removeObject() {
        console.log("[Control Button] Remove Object clicked.");
        let targetObject = selectedObject || mesh; // Target selected object, or the whole model
        if (targetObject) {
            scene.remove(targetObject);
            targetObject.traverse(obj => { // Dispose resources
                if (obj.isMesh) {
                    if (obj.geometry) obj.geometry.dispose();
                    if (obj.material) {
                        if (Array.isArray(obj.material)) {
                            obj.material.forEach(m => m.dispose());
                        } else {
                            m.dispose();
                        }
                    }
                }
            });
            if (targetObject === mesh) { // If main model was removed
                mesh = null;
                addMessageToLog('AI', "Model removed.");
                speakResponse("Model removed.");
                // Go back to upload page if main model is removed
                goBack(); // This will also clear selection
            } else { // If a specific part was removed
                addMessageToLog('AI', `Part '${targetObject.name || 'unnamed part'}' removed.`);
                speakResponse(`Part removed.`);
                clearSelection(); // Clear selection after removal
            }
        } else {
            addMessageToLog('AI', "No object or part to remove.");
            speakResponse("No object or part to remove.");
        }
    }
    // Make removeObject globally accessible
    window.removeObject = removeObject;


    function resetView() {
        console.log("[Control Button] Reset View clicked.");
        if (mesh) { // Resetting view always applies to the whole loaded model
            mesh.rotation.set(0, 0, 0); // Reset rotation of the main model
            mesh.position.set(0, 0, 0); // Reset position of the main model

            // Recenter and re-frame camera
            const bbox = new THREE.Box3().setFromObject(mesh);
            const center = bbox.getCenter(new THREE.Vector3());
            mesh.position.sub(center); // Center the model's group

            const size = bbox.getSize(new THREE.Vector3());
            const maxDim = Math.max(size.x, size.y, size.z);
            camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
            camera.lookAt(0, 0, 0);
            controls.update();
            addMessageToLog('AI', "View reset.");
            speakResponse("View reset.");
        } else {
            addMessageToLog('AI', "No model to reset view for.");
            speakResponse("No model to reset view for.");
        }
    }
    // Make resetView globally accessible
    window.resetView = resetView;

    function showDesignInfo() {
        console.log("[Control Button] Design Info clicked.");
        let targetObject = selectedObject || mesh; // Get info for selected object or whole model
        if (!targetObject) {
            addMessageToLog('AI', "No design loaded or part selected.");
            speakResponse("No design loaded or part selected.");
            return;
        }
        const bbox = new THREE.Box3().setFromObject(targetObject);
        const size = new THREE.Vector3();
        bbox.getSize(size);
        const info = `Name: ${targetObject.name || 'Unnamed'}\n` +
                     `Width: ${size.x.toFixed(2)}\nHeight: ${size.y.toFixed(2)}\nDepth: ${size.z.toFixed(2)}\n` +
                     `Position: X:${targetObject.position.x.toFixed(2)}, Y:${targetObject.position.y.toFixed(2)}, Z:${targetObject.position.z.toFixed(2)}`;
        addMessageToLog('AI', info.replace(/\n/g, ', '));
        speakResponse(info);
    }
    // Make showDesignInfo globally accessible
    window.showDesignInfo = showDesignInfo;

    // --- Raycasting and Selection ---
    function onCanvasClick(event) {
        // Calculate mouse position in normalized device coordinates (-1 to +1)
        const rect = renderer.domElement.getBoundingClientRect();
        if (event.changedTouches) { // Handle touch events
            mouse.x = ((event.changedTouches[0].clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.changedTouches[0].clientY - rect.top) / rect.height) * 2 + 1;
        } else { // Handle mouse events
            mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
        }

        raycaster.setFromCamera(mouse, camera);

        // Intersect with all children of the main loaded glTF scene object (`mesh`)
        // This allows selecting individual parts/meshes if the glTF has them
        const intersects = raycaster.intersectObjects(mesh ? mesh.children : [], true); // Only intersect if mesh exists

        if (intersects.length > 0) {
            let clickedObject = null;
            for (const intersect of intersects) {
                // Ensure it's a visible mesh and not just a group or part of the background
                if (intersect.object.isMesh && intersect.object.visible && intersect.object.material) {
                    clickedObject = intersect.object;
                    break;
                }
            }

            if (clickedObject) {
                if (selectedObject && selectedObject !== clickedObject) {
                    // Restore original material of previously selected object if it's different
                    restoreOriginalMaterial(selectedObject);
                }

                if (selectedObject !== clickedObject) { // If a new object is selected
                    selectedObject = clickedObject;
                    storeAndHighlight(selectedObject);
                    addMessageToLog('System', `Object '${selectedObject.name || 'unnamed object'}' selected.`);
                    speakResponse(`Object selected.`);
                } else { // If the same object is clicked again, deselect it
                    clearSelection();
                }
            }
        } else {
            clearSelection(); // If clicked outside, clear selection
        }
    }

    function storeAndHighlight(object) {
        object.traverse((child) => {
            if (child.isMesh && child.material) {
                if (Array.isArray(child.material)) {
                    child.material.forEach((m, index) => {
                        const uuidKey = `${child.uuid}-${index}`;
                        if (!originalMaterials.has(uuidKey)) {
                            // Store a clone of the material to preserve its original state (including map)
                            originalMaterials.set(uuidKey, m.clone());
                        }
                        // Create a new material for highlighting to avoid modifying the original
                        const highlightMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
                        child.material[index] = highlightMaterial;
                        child.material[index].needsUpdate = true;
                    });
                } else {
                    const uuidKey = child.uuid;
                    if (!originalMaterials.has(uuidKey)) {
                        // Store a clone of the material to preserve its original state (including map)
                        originalMaterials.set(uuidKey, child.material.clone());
                    }
                    // Create a new material for highlighting to avoid modifying the original
                    const highlightMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
                    child.material = highlightMaterial;
                    child.material.needsUpdate = true;
                }
            }
        });
    }

    function restoreOriginalMaterial(object) {
        object.traverse((child) => {
            if (child.isMesh && child.material) {
                if (Array.isArray(child.material)) {
                    child.material.forEach((m, index) => {
                        const uuidKey = `${child.uuid}-${index}`;
                        const originalMat = originalMaterials.get(uuidKey);
                        if (originalMat) {
                            child.material[index] = originalMat; // Restore the entire material
                            originalMaterials.delete(uuidKey);
                            child.material[index].needsUpdate = true;
                        }
                    });
                } else {
                    const uuidKey = child.uuid;
                    const originalMat = originalMaterials.get(uuidKey);
                    if (originalMat) {
                        child.material = originalMat; // Restore the entire material
                        originalMaterials.delete(uuidKey);
                        child.material.needsUpdate = true;
                    }
                }
            }
        });
    }

    function clearSelection() {
        if (selectedObject) {
            restoreOriginalMaterial(selectedObject); // Use the new function
            selectedObject = null;
            addMessageToLog('System', 'Selection cleared.');
            speakResponse('Selection cleared.');
        }
    }

    // --- AI Interaction Panel Functions ---
    function addMessageToLog(sender, message) {
        const p = document.createElement('p');
        p.textContent = `${sender}: ${message}`;
        p.classList.add(sender === 'User' ? 'user-message' : (sender === 'AI' ? 'ai-response' : 'system-message'));
        aiLog.appendChild(p);
        aiLog.scrollTop = aiLog.scrollHeight;
        return p; // Return the created element
    }

    sendTextCommandBtn.addEventListener('click', () => {
        const command = textCommandInput.value.trim();
        if (command) {
            addMessageToLog('User', command);
            processAICommand(command);
            textCommandInput.value = '';
        }
    });

    textCommandInput.addEventListener('keypress', (event) => {
        if (event.key === 'Enter') {
            sendTextCommandBtn.click();
        }
    });

    // --- AI Voice Assist Functions ---
    voiceAssistBtn.addEventListener('click', toggleVoiceAssist);

    function initializeSpeechRecognition() {
        if (!('webkitSpeechRecognition' in window)) {
            addMessageToLog('System', "Speech recognition not supported in this browser. Please use Google Chrome.");
            return null;
        }
        const newRecognition = new webkitSpeechRecognition();
        newRecognition.continuous = true;
        newRecognition.interimResults = false;
        newRecognition.lang = 'en-US';
        return newRecognition;
    }

    function initializeSpeechSynthesis() {
        if (!('speechSynthesis' in window)) {
            addMessageToLog('System', "Speech synthesis not supported in this browser.");
            return null;
        }
        return window.speechSynthesis;
    }

    function speakResponse(text) {
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) {
                console.warn("Speech synthesis not available or failed to initialize.");
                return;
            }
        }
        synth.cancel();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'en-US';
        utterance.onend = () => {
            console.log('Speech synthesis ended');
            if (isVoiceAssistActive && recognition && !synth.speaking) {
                setTimeout(() => {
                    addMessageToLog('System', "Listening...");
                    recognition.start();
                }, 1500);
            }
        };
        utterance.onerror = (event) => {
            console.error('Speech synthesis error:', event);
            addMessageToLog('System', "Error speaking response. Attempting to reinitialize speech synthesis.");
            // Invalidate the current synth object to force re-initialization next time
            synth = null;
        };
        synth.speak(utterance);
    }

    function toggleVoiceAssist() {
        if (!mesh) {
            addMessageToLog('AI', "Please load a 3D model first.");
            speakResponse("Please load a 3D model first.");
            return;
        }

        if (!recognition) {
            recognition = initializeSpeechRecognition();
            if (!recognition) return;
        }
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }

        if (isVoiceAssistActive) {
            stopVoiceAssist();
            speakResponse("Voice assist stopped. Goodbye!");
        } else {
            isVoiceAssistActive = true;
            voiceAssistBtn.classList.add('active-voice-btn');
            voiceAssistBtn.innerHTML = '❌ Stop AI Voice';
            aiInteractionPanel.classList.add('active');
            addMessageToLog('System', "Starting voice assist...");

            speakResponse("Hi, what can I help you with?");
        }

        recognition.onstart = function () {
            addMessageToLog('System', "Listening...");
            console.log('[Speech Recognition] Started listening.');
        };

        recognition.onresult = function (event) {
            console.log('[Speech Recognition] onresult event received:', event); // Log the raw event
            const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
            addMessageToLog('User', transcript);
            addMessageToLog('System', "Processing voice command...");
            console.log('[Speech Recognition] Speech recognized:', transcript);

            recognition.stop();
            processAICommand(transcript);
        };

        recognition.onerror = function (event) {
            console.error('[Speech Recognition] Error:', event); // Log the raw error event
            let errorMessage = "An unknown speech recognition error occurred.";
            if (event.error === 'not-allowed') {
                errorMessage = "Microphone access denied. Please allow microphone access in your browser settings.";
            } else if (event.error === 'no-speech') {
                errorMessage = "No speech detected. Please try speaking louder or clearer.";
            } else if (event.error) {
                errorMessage = `Speech error: ${event.error}. Please try again.`;
            }
            addMessageToLog('System', errorMessage);
            speakResponse(errorMessage);
            stopVoiceAssist();
        };

        recognition.onend = function () {
            console.log('[Speech Recognition] Ended.');
            // If voice assist is still active, restart listening after a brief delay
            if (isVoiceAssistActive && !synth.speaking) {
                setTimeout(() => {
                    if (isVoiceAssistActive) {
                        addMessageToLog('System', "Listening again...");
                        recognition.start();
                    }
                }, 1000);
            }
        };
    }

    function stopVoiceAssist() {
        isVoiceAssistActive = false;
        if (recognition && typeof recognition.stop === 'function') {
            recognition.stop();
        }
        if (synth && typeof synth.cancel === 'function') {
            synth.cancel();
        }
        aiInteractionPanel.classList.remove('active');
        voiceAssistBtn.classList.remove('active-voice-btn');
        voiceAssistBtn.innerHTML = '🧠 AI Voice Assist';
        addMessageToLog('System', "Voice assist stopped.");
    }

    // --- AI Command Processing (Core Logic) ---
    async function processAICommand(command) {
        console.log(`[AI Command Processing] Received command: "${command}"`);

        // Handle common greetings explicitly
        const greetingKeywords = ['hi', 'hello', 'hey', 'good morning', 'good afternoon', 'good evening'];
        if (greetingKeywords.some(keyword => command.includes(keyword))) {
            addMessageToLog('AI', "Hello there! How can I help you with your 3D model today?");
            speakResponse("Hello there! How can I help you with your 3D model today?");
            console.log(`[AI Command Processing] Handling greeting: "${command}"`);
            return;
        }

        // Handle pre-defined UI commands first
        if (command.includes("select object") || command.includes("select part")) {
            if (selectedObject) {
                speakResponse("An object is already selected. Click on a different part to change selection or click outside to clear.");
            } else if (mesh) {
                speakResponse("Please click on a part of the model to select it.");
            } else {
                speakResponse("No model loaded to select.");
            }
            return;
        } else if (command.includes("clear selection") || command.includes("deselect")) {
            clearSelection();
            speakResponse("Selection cleared.");
            return;
        }

        let loadingMessageElement = null; // Declare here to be accessible in catch and finally

        try {
            // Updated payload for AI to include new commands
            const payloadCommands = [ // Define the commands array here
                    {
                        name: "rotate",
                        description: "Rotates the entire loaded 3D model around its Y-axis by a specified degree. Use for general model rotation.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                value: { type: "NUMBER", description: "Degrees to rotate (e.g., 90, -45)." }
                            },
                            required: ["value"]
                        }
                    },
                    {
                        name: "rotateSelected",
                        description: "Rotates the currently selected 3D part around its Y-axis by a specified degree. Use for rotating individual parts.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                value: { type: "NUMBER", description: "Degrees to rotate (e.g., 90, -45)." }
                            },
                            required: ["value"]
                        }
                    },
                    {
                        name: "scale",
                        description: "Scales the entire loaded 3D model by a specified factor. Use for general model resizing.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                value: { type: "NUMBER", description: "Scale factor (e.g., 0.5 for half, 2 for double). Must be positive." }
                            },
                            required: ["value"]
                        }
                    },
                    {
                        name: "scaleSelected",
                        description: "Scales the currently selected 3D part by a specified factor. Use for resizing individual parts.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                value: { type: "NUMBER", description: "Scale factor (e.g., 0.5 for half, 2 for double). Must be positive." }
                            },
                            required: ["value"]
                        }
                    },
                    {
                        name: "translate",
                        description: "Moves the entire loaded 3D model by specified X, Y, Z offsets. Use for general model positioning.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                x: { type: "NUMBER", description: "X-axis offset." },
                                y: { type: "NUMBER", description: "Y-axis offset." },
                                z: { type: "NUMBER", description: "Z-axis offset." }
                            }
                        }
                    },
                    {
                        name: "translateSelected",
                        description: "Moves the currently selected 3D part by specified X, Y, Z offsets. Use for positioning individual parts.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                x: { type: "NUMBER", description: "X-axis offset." },
                                y: { type: "NUMBER", description: "Y-axis offset." },
                                z: { type: "NUMBER", description: "Z-axis offset." }
                            }
                        }
                    },
                    {
                        name: "color",
                        description: "Changes the color of the entire loaded 3D model using a hexadecimal color code. Use for general model coloring.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                value: { type: "STRING", description: "Hexadecimal color code (e.g., #FF0000 for red)." }
                            },
                            required: ["value"]
                        }
                    },
                    {
                        name: "colorSelected",
                        description: "Changes the color of the currently selected 3D part using a hexadecimal color code. Use for coloring individual parts.",
                        parameters: {
                            type: "OBJECT",
                            properties: {
                                value: { type: "STRING", description: "Hexadecimal color code (e.g., #00FF00 for green)." }
                            },
                            required: ["value"]
                        }
                    },
                    {
                        name: "hide",
                        description: "Hides the entire loaded 3D model. Use for toggling model visibility.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "hideSelected",
                        description: "Hides the currently selected 3D part. Use for toggling individual part visibility.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "show",
                        description: "Shows the entire loaded 3D model if it was hidden. Use for toggling model visibility.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "showSelected",
                        description: "Shows the currently selected 3D part if it was hidden. Use for toggling individual part visibility.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "duplicate",
                        description: "Duplicates the entire loaded 3D model. The duplicate will be slightly offset.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "duplicateSelected",
                        description: "Duplicates the currently selected 3D part. The duplicate will be slightly offset.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "removeObject",
                        description: "Removes the entire loaded 3D model from the scene.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "removeSelected",
                        description: "Removes the currently selected 3D part from the scene.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "resetView",
                        description: "Resets the camera view and model position/rotation to their initial state.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "designInfo",
                        description: "Provides information about the loaded 3D model or selected part, such as dimensions and position.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "zoomIn",
                        description: "Zooms the camera closer to the model.",
                        parameters: { type: "OBJECT", properties: {} }
                    },
                    {
                        name: "zoomOut",
                        description: "Zooms the camera further from the model.",
                        parameters: { type: "OBJECT", properties: {} }
                    }
                ];

            const payload = {
                contents: [{ role: "user", parts: [{ text: command }] }],
                toolConfig: {
                    functionCallingConfig: {
                        mode: "ANY",
                        allowedFunctionNames: payloadCommands.map(cmd => cmd.name)
                    }
                },
                tools: [{ functionDeclarations: payloadCommands }]
            };

            // Create and append the loading message element BEFORE the fetch
            loadingMessageElement = addMessageToLog('System', 'AI is thinking...'); // Use the helper function and get the element

            const aiReply = await sendToAIInternal(payload); // Call the internal function

            let resultData;
            try {
                resultData = JSON.parse(aiReply.content);
                console.log("[AI Command Processing] Parsed AI command:", resultData);
            } catch (e) {
                resultData = { action: 'conversational', value: aiReply.content };
                console.log("[AI Command Processing] Parsed AI conversational response (JSON parse failed):", resultData);
            }

            if (resultData && typeof resultData === 'object' && resultData.action) {
                let target = selectedObject || mesh; // Target the selected object, or the whole model if nothing is selected

                // Log the target object
                console.log(`[Action Execution] Target object for action '${resultData.action}':`, target ? (target.name || target.uuid) : "None (mesh/selectedObject is null)");

                // Handle cases where an action requires a selected object but none is present
                const requiresSelection = ['rotateSelected', 'scaleSelected', 'translateSelected', 'colorSelected', 'hideSelected', 'showSelected', 'duplicateSelected', 'removeSelected'];
                if (requiresSelection.includes(resultData.action) && !selectedObject) {
                    addMessageToLog('AI', "Please select a part of the model first to perform that action.");
                    speakResponse("Please select a part of the model first to perform that action.");
                    // Remove loading message here if an early return happens
                    if (loadingMessageElement && loadingMessageElement.parentNode === aiLog) {
                        aiLog.removeChild(loadingMessageElement);
                    }
                    return;
                }

                switch (resultData.action) {
                    case 'rotate':
                    case 'rotateSelected':
                        if (target && typeof resultData.value === 'number') {
                            console.log(`[Three.js Property Check] Before rotate: target.rotation.y = ${target.rotation.y}`);
                            // THREE.MathUtils.degToRad is now directly available via THREE
                            target.rotation.y += THREE.MathUtils.degToRad(resultData.value);
                            console.log(`[Three.js Property Check] After rotate: target.rotation.y = ${target.rotation.y}`);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} rotated by ${resultData.value} degrees.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} rotated by ${resultData.value} degrees.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't rotate. Please specify a valid degree value or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't rotate.");
                        }
                        break;
                    case 'scale':
                    case 'scaleSelected':
                        if (target && typeof resultData.value === 'number' && resultData.value > 0) {
                            console.log(`[Three.js Property Check] Before scale: target.scale.x = ${target.scale.x}`);
                            // Corrected to use setScalar for uniform scaling
                            target.scale.setScalar(resultData.value);
                            console.log(`[Three.js Property Check] After scale: target.scale.x = ${target.scale.x}`);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} scaled by a factor of ${resultData.value}.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} scaled by a factor of ${resultData.value}.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't scale. Please specify a positive scale factor or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't scale.");
                        }
                        break;
                    case 'translate':
                    case 'translateSelected':
                        if (target && typeof resultData.value === 'object' &&
                            !isNaN(resultData.value.x) && !isNaN(resultData.value.y) && !isNaN(resultData.value.z)) {
                            console.log(`[Three.js Property Check] Before translate: target.position = ${JSON.stringify(target.position)}`);
                            target.position.x += resultData.value.x || 0;
                            target.position.y += resultData.value.y || 0;
                            target.position.z += resultData.value.z || 0;
                            console.log(`[Three.js Property Check] After translate: target.position = ${JSON.stringify(target.position)}`);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} moved by X:${resultData.value.x || 0}, Y:${resultData.value.y || 0}, Z:${resultData.value.z || 0} units.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} moved.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't move. Please specify valid X, Y, and Z values or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't move.");
                        }
                        break;
                    case 'color':
                    case 'colorSelected':
                        if (target && typeof resultData.value === 'string' && /^#([0-9A-F]{3}){1,2}$/i.test(resultData.value)) {
                            const newColor = new THREE.Color(resultData.value);
                            console.log(`[Action Execution] Attempting to change color of ${selectedObject ? 'selected part' : 'model'} to ${resultData.value}`);

                            target.traverse((child) => {
                                if (child.isMesh) {
                                    if (Array.isArray(child.material)) {
                                        child.material.forEach(m => {
                                            if (m instanceof THREE.MeshStandardMaterial || m instanceof THREE.MeshBasicMaterial) {
                                                // Store original material state if not already stored (for selected object)
                                                // This part is handled by storeAndHighlight for selection.
                                                // For direct color change, we apply the color directly.
                                                m.color.set(newColor);
                                                // If a texture map exists, remove it to make the solid color visible
                                                if (m.map) {
                                                    console.log(`[Three.js Property Check] Material had a map, setting map to null for visibility.`);
                                                    m.map = null;
                                                    m.needsUpdate = true; // Important for material changes to take effect
                                                }
                                                console.log(`[Three.js Property Check] Material color set to: ${m.color.getHexString()}`);
                                            }
                                        });
                                    } else if (child.material) {
                                        const m = child.material;
                                        if (m instanceof THREE.MeshStandardMaterial || m instanceof THREE.MeshBasicMaterial) {
                                            // Store original material state if not already stored (for selected object)
                                            // This part is handled by storeAndHighlight for selection.
                                            // For direct color change, we apply the color directly.
                                            m.color.set(newColor);
                                            // If a texture map exists, remove it to make the solid color visible
                                            if (m.map) {
                                                console.log(`[Three.js Property Check] Material had a map, setting map to null for visibility.`);
                                                m.map = null;
                                                m.needsUpdate = true; // Important for material changes to take effect
                                            }
                                            console.log(`[Three.js Property Check] Material color set to: ${m.color.getHexString()}`);
                                        }
                                    }
                                }
                            });

                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} color changed to ${resultData.value}.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} color changed.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't change the color. Please provide a valid hexadecimal color code, or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't change the color.");
                        }
                        break;
                    case 'hide':
                    case 'hideSelected':
                        if (target) {
                            target.visible = false;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} is now hidden.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} is now hidden.`);
                            if (selectedObject === target) clearSelection(); // Deselect if hidden
                        } else {
                            addMessageToLog('AI', "No model or part to hide.");
                            speakResponse("No model or part to hide.");
                        }
                        break;
                    case 'show':
                    case 'showSelected':
                        if (target) {
                            target.visible = true;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} is now visible.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} is now visible.`);
                        } else {
                            addMessageToLog('AI', "No model or part to show.");
                            speakResponse("No model or part to show.");
                        }
                        break;
                    case 'duplicate':
                    case 'duplicateSelected':
                        if (target) {
                            const newObject = target.clone();
                            newObject.position.x += 10; // Offset slightly
                            newObject.position.y += 10;
                            scene.add(newObject);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} duplicated.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} duplicated.`);
                        } else {
                            addMessageToLog('AI', "No model or part to duplicate.");
                            speakResponse("No model or part to duplicate.");
                        }
                        break;
                    case 'removeObject':
                    case 'removeSelected': // AI might send this for selected object
                        removeObject(); // This function now handles selectedObject vs mesh
                        break;
                    case 'resetView': // This command always applies to the whole scene
                        resetView();
                        break;
                    case 'designInfo': // This command always applies to selected or whole model
                        showDesignInfo();
                        break;
                    case 'zoomIn':
                        if (camera) {
                            camera.fov = Math.max(10, camera.fov - 5); // Decrease FOV to zoom in
                            camera.updateProjectionMatrix();
                            controls.update();
                            addMessageToLog('AI', `Zoomed in. Current FOV: ${camera.fov.toFixed(2)}.`);
                            speakResponse("Zoomed in.");
                        } else {
                            addMessageToLog('AI', "No camera available to zoom.");
                            speakResponse("No camera available to zoom.");
                        }
                        break;
                    case 'zoomOut':
                        if (camera) {
                            camera.fov = Math.min(100, camera.fov + 5); // Increase FOV to zoom out
                            camera.updateProjectionMatrix();
                            controls.update();
                            addMessageToLog('AI', `Zoomed out. Current FOV: ${camera.fov.toFixed(2)}.`);
                            speakResponse("Zoomed out.");
                        } else {
                            addMessageToLog('AI', "No camera available to zoom.");
                            speakResponse("No camera available to zoom.");
                        }
                        break;
                    case 'conversational':
                        let responseText = resultData.value || resultData.message;
                        if (responseText) {
                            addMessageToLog('AI', responseText);
                            speakResponse(responseText);
                        } else {
                            addMessageToLog('AI', "I received a conversational response but it was empty.");
                            speakResponse("I received a conversational response but it was empty.");
                        }
                        break;
                    case 'error':
                        addMessageToLog('AI', `An AI error occurred: ${resultData.value}. Please try again.`);
                        speakResponse("An error occurred with the AI. Please try again.");
                        console.error("AI returned an error action:", resultData.value);
                        break;
                    default:
                        addMessageToLog('AI', "The AI sent an unrecognized command. Please try again.");
                        speakResponse("The AI sent an unrecognized command. Please try again.");
                        console.warn("AI sent unrecognized action:", resultData.action);
                        break;
                }
            } else {
                addMessageToLog('AI', "I received an unexpected AI response. Please try again.");
                speakResponse("I received an unexpected AI response. Please try again.");
                console.error("Unexpected AI response format:", resultData);
            }
        } catch (error) {
            console.error("Error processing AI command:", error);
            addMessageToLog('AI', "I'm sorry, I encountered an error while processing your command. Please try again.");
            speakResponse("I'm sorry, I encountered an error. Please try again.");
        } finally { // Ensure loading message is removed in all cases
            if (loadingMessageElement && loadingMessageElement.parentNode === aiLog) {
                aiLog.removeChild(loadingMessageElement);
            }
        }
    }

    // Renamed sendToAI to sendToAIInternal to avoid confusion with the outer processAICommand flow
    async function sendToAIInternal(payload) {
        sendTextCommandBtn.disabled = true;
        textCommandInput.disabled = true;

        try {
            const apiKey = ""; // Leave this as-is; Canvas will provide the key
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                // More specific error message for 403
                if (response.status === 403) {
                    throw new Error(`API Access Denied (403). Please ensure your API key is valid and has permissions for Gemini 2.0 Flash.`);
                } else {
                    throw new Error(`Backend error: ${errorData.message || response.statusText}`);
                }
            }

            const result = await response.json();
            console.log("[AI Response Raw] Full result object:", result); // Log the full result object

            // Process the AI response to extract content or tool calls
            if (result.candidates && result.candidates.length > 0 && result.candidates[0].content) {
                const candidateContent = result.candidates[0].content;
                if (candidateContent.parts && candidateContent.parts.length > 0) {
                    // Check for tool calls first
                    const toolCall = candidateContent.parts.find(part => part.functionCall);
                    if (toolCall) {
                        const functionCall = toolCall.functionCall;
                        return {
                            content: JSON.stringify({
                                action: functionCall.name,
                                value: functionCall.args
                            })
                        };
                    }
                    // If no tool call, return text content
                    const textPart = candidateContent.parts.find(part => part.text);
                    if (textPart) {
                        return { content: textPart.text };
                    }
                }
            }
            return { content: "AI did not provide a valid response." };

        } finally {
            sendTextCommandBtn.disabled = false;
            textCommandInput.disabled = false;
        }
    }
</script>
</body>
</html>
