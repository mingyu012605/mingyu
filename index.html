<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI VR CAD Editor</title>
    <link rel="stylesheet" href="styles.css"> <!-- Ensure this links to your styles (1).css -->
    <style>
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            font-family: 'Segoe UI', sans-serif;
            background: #f2f4f8;
            overflow: hidden;
            display: flex;
            flex-direction: column;
        }

        header {
            background-color: #10131c;
            padding: 20px;
            color: white;
            text-align: center;
            font-size: 2.5rem;
            font-weight: bold;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 15px;
            flex-shrink: 0;
            height: 80px;
            box-sizing: border-box;
        }

        header svg {
            height: 40px;
            width: 40px;
        }

        .page-container {
            display: flex;
            flex-direction: column;
            flex-grow: 1;
            width: 100%;
            position: relative;
        }

        .page {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            transition: opacity 0.5s ease-in-out;
        }

        .page-active {
            opacity: 1;
            pointer-events: auto;
            z-index: 1;
        }

        .page-inactive {
            opacity: 0;
            pointer-events: none;
            z-index: 0;
        }

        /* Upload Page */
        #uploadPage {
            background-color: #f2f4f8;
            color: #333;
        }

        .upload-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            background: white;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
        }

        .upload-content h2 {
            color: #10131c;
            margin-bottom: 20px;
            font-size: 2em;
        }

        #dropZone {
            width: 400px;
            height: 150px;
            border: 2px dashed #aaa;
            border-radius: 8px;
            display: flex;
            justify-content: center;
            align-items: center;
            text-align: center;
            color: #555;
            cursor: pointer;
            transition: border-color 0.3s ease;
            font-size: 1.1em;
            background-color: #fafafa;
        }

        #dropZone:hover {
            border-color: #007bff;
        }

        #fileInput {
            display: none;
        }

        .button-group {
            display: flex;
            gap: 15px;
            margin-top: 20px;
        }

        .button {
            padding: 12px 25px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 1em;
            font-weight: bold;
            transition: background-color 0.3s ease, transform 0.2s ease;
        }

        .button.primary {
            background-color: #007bff;
            color: white;
        }

        .button.primary:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
        }

        .button.secondary {
            background-color: #6c757d;
            color: white;
        }

        .button.secondary:hover {
            background-color: #5a6268;
            transform: translateY(-2px);
        }

        #loadingMsg {
            display: none;
            margin-top: 20px;
            color: #007bff;
            font-size: 1.1em;
        }

        /* Editor Page */
        #editorPage {
            background-color: #1e1f26;
            flex-direction: row;
            justify-content: flex-start;
            align-items: stretch;
            padding: 0;
            box-sizing: border-box;
        }

        .sidebar {
            width: 280px;
            background-color: #2a2c37;
            padding: 20px;
            display: flex;
            flex-direction: column;
            border-right: 1px solid #3d3f4b;
            box-shadow: 2px 0 5px rgba(0, 0, 0, 0.2);
            flex-shrink: 0;
            overflow-y: auto;
        }

        .sidebar h2 {
            color: #fff;
            margin-bottom: 25px;
            font-size: 1.8em;
            border-bottom: 2px solid #007bff;
            padding-bottom: 10px;
        }

        .editor-controls {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin-bottom: 30px;
        }

        .control-button {
            width: 100%;
            padding: 12px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 1em;
            font-weight: bold;
            transition: background-color 0.3s ease, transform 0.2s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
        }

        .control-button:hover {
            background-color: #0056b3;
            transform: translateY(-2px);
        }

        .control-button svg {
            fill: white;
            height: 20px;
            width: 20px;
        }

        #cadViewer {
            flex-grow: 1;
            background-color: #1e1f26;
            position: relative;
        }

        #cadCanvas {
            display: block;
            width: 100%;
            height: 100%;
        }

        /* AI Interaction Panel */
        #aiInteractionPanel {
            background-color: #2a2c37;
            border-top: 1px solid #3d3f4b;
            padding: 15px;
            display: flex;
            flex-direction: column;
            gap: 10px;
            flex-shrink: 0;
            height: auto;
            max-height: 40%;
            overflow: hidden;
            transition: all 0.3s ease-in-out;
            position: absolute;
            bottom: 0;
            width: 100%;
            left: 0;
            box-sizing: border-box;
            transform: translateY(100%);
            opacity: 0;
        }

        #aiInteractionPanel.active {
            transform: translateY(0);
            opacity: 1;
            max-height: 80%;
        }


        #aiLog {
            flex-grow: 1;
            background-color: #1e1f26;
            border-radius: 8px;
            padding: 10px;
            color: #e0e0e0;
            overflow-y: auto;
            height: 150px;
            flex-shrink: 1;
        }

        #aiLog p {
            margin: 5px 0;
            line-height: 1.4;
        }

        .user-message {
            color: #00ffff;
            text-align: right;
        }

        .ai-response {
            color: #00ff00;
            text-align: left;
        }

        .system-message {
            color: #ffcc00;
            text-align: center;
            font-style: italic;
        }

        .ai-input-group {
            display: flex;
            gap: 10px;
            flex-shrink: 0;
        }

        #textCommandInput {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #3d3f4b;
            border-radius: 6px;
            background-color: #1e1f26;
            color: white;
            font-size: 1em;
        }

        #textCommandInput::placeholder {
            color: #999;
        }

        #sendTextCommandBtn {
            padding: 10px 15px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 1em;
            font-weight: bold;
            transition: background-color 0.3s ease;
        }

        #sendTextCommandBtn:hover {
            background-color: #0056b3;
        }

        #voiceAssistBtn {
            background-color: #6c757d;
            border: none;
            border-radius: 8px;
            padding: 15px 20px;
            font-size: 1.1em;
            font-weight: bold;
            color: white;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease;
            position: absolute;
            bottom: 20px;
            right: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
            z-index: 10;
        }

        #voiceAssistBtn:hover {
            background-color: #5a6268;
            transform: translateY(-2px);
        }

        #voiceAssistBtn.active-voice-btn {
            background-color: #dc3545;
        }

        #voiceAssistBtn.active-voice-btn:hover {
            background-color: #c82333;
        }
    </style>
    <!-- Import Map for ES Modules -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.128.0/examples/jsm/"
            }
        }
    </script>
</head>
<body>
    <header>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path fill="currentColor" d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-1 17.93c-3.95-.49-7-3.85-7-7.93 0-.62.08-1.21.21-1.79L9 15v1c0 1.1.9 2 2 2v-.07zm6.93-2.61c.6.93.97 2.02 1.07 3.18H12v-4.17c3.15-.36 5.61-2.96 5.93-6.18l.1-1c-.06-.11-.12-.2-.18-.31l-3.21-3.21C14.75 6.64 14 7.7 14 9c0 2.21 1.79 4 4 4 .77 0 1.47-.22 2.07-.6l.1-.1c.36-.6.56-1.3.56-2.06 0-2.76-2.24-5-5-5-1.01 0-1.95.3-2.73.83L9.07 5.07c-2.43 2.43-2.43 6.36 0 8.79l2.83 2.83-2.83 2.83c-2.43 2.43-6.36 2.43-8.79 0L2 15.07c.2-.2.39-.4.59-.6l2.83-2.83c2.43-2.43 2.43-6.36 0-8.79L3.93 3.93c.2-.2.4-.39.6-.59l2.83 2.83c2.43 2.43 6.36 2.43 8.79 0l2.83-2.83c.2.2.39.4.59.6l-2.83 2.83z"/>
        </svg>
        AI VR CAD Editor
    </header>

    <div class="page-container">
        <section id="uploadPage" class="page page-active">
            <div class="upload-content">
                <h2>Upload your 3D Model</h2>
                <div id="dropZone">Drag and Drop your .gltf or .glb file(s) here</div>
                <input type="file" id="fileInput" accept=".gltf,.glb" />
                <button class="button primary" id="loadEditorButton">Load Model & Go to Editor</button>
                <p id="loadingMsg">Loading model, please wait...</p>
            </div>
        </section>

        <section id="editorPage" class="page page-inactive">
            <aside class="sidebar">
                <h2>Controls</h2>
                <div class="editor-controls">
                    <button class="control-button" onclick="removeObject()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M6 19c0 1.1.9 2 2 2h8c1.1 0 2-.9 2-2V7H6v12zm2.46-7.12l1.41-1.41L12 12.59l2.12-2.12 1.41 1.41L13.41 14l2.12 2.12-1.41 1.41L12 15.41l-2.12 2.12-1.41-1.41L10.59 14l-2.13-2.12zM15.5 4l-1-1h-5l-1 1H5v2h14V4h-3.5z"/></svg>
                        Remove Object
                    </button>
                    <button class="control-button" onclick="resetView()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M12 4C7.31 4 3.07 5.9 0 8.98L12 21 24 8.98C20.93 5.9 16.69 4 12 4zm0 2.98c2.18 0 4.2.82 5.74 2.37L12 18.06 6.26 9.35C7.8 7.8 9.82 6.98 12 6.98z"/></svg>
                        Reset View
                    </button>
                    <button class="control-button" onclick="showDesignInfo()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M11 7h2v2h-2zm0 4h2v6h-2zm1-9C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8z"/></svg>
                        Design Info
                    </button>
                    <button class="control-button" onclick="goBack()">
                        <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 0 24 24" width="24px" fill="#FFFFFF"><path d="M12 2c5.52 0 10 4.48 10 10s-4.48 10-10 10S2 17.52 2 12 6.48 2 12 2zm0 18c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8zm-1-13v4H7.5L12 16.5 16.5 12H13V7z"/></svg>
                        Back to Upload
                    </button>
                </div>

                <h2>AI Chat Log</h2>
                <div id="aiLog">
                    <p class="system-message">System: AI Chat Log Initialized.</p>
                </div>
                <div class="ai-input-group">
                    <input type="text" id="textCommandInput" placeholder="Type AI command or question..." />
                    <button id="sendTextCommandBtn">Send</button>
                </div>
            </aside>

            <main id="cadViewer">
                <canvas id="cadCanvas"></canvas>
            </main>
            <button id="voiceAssistBtn">🧠 AI Voice Assist</button>
            <div id="aiInteractionPanel"></div>
        </section>
    </div>

<script type="module">
    // Import Three.js and its modules
    import * as THREE from 'three';
    import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
    import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
    import { VRButton } from 'three/addons/webxr/VRButton.js';

    // Global map to store dropped files by their relative path (e.g., "scene.bin", "textures/image.png")
    const droppedFileBlobs = new Map();

    let uploadedFile = null, scene, camera, renderer, mesh, controls;
    let recognition;
    let synth;
    let isVoiceAssistActive = false;
    let raycaster;
    let mouse;
    let selectedObject = null; // This will hold the currently selected THREE.Mesh part
    const originalColors = new Map(); // Map to store original colors (hex value) by object UUID

    // Get references to HTML elements
    const fileInput = document.getElementById('fileInput');
    const dropZone = document.getElementById('dropZone');
    const loadingMsg = document.getElementById('loadingMsg');
    const uploadPage = document.getElementById('uploadPage');
    const editorPage = document.getElementById('editorPage');
    const voiceAssistBtn = document.getElementById('voiceAssistBtn');
    const aiInteractionPanel = document.getElementById('aiInteractionPanel');
    const aiLog = document.getElementById('aiLog');
    const textCommandInput = document.getElementById('textCommandInput');
    const sendTextCommandBtn = document.getElementById('sendTextCommandBtn');
    const cadCanvas = document.getElementById('cadCanvas'); // Reference to the canvas element
    const loadEditorButton = document.getElementById('loadEditorButton'); // Reference to the new button ID

    // --- File Input and Page Navigation ---
    dropZone.addEventListener('click', () => fileInput.click());
    dropZone.addEventListener('dragover', e => { e.preventDefault(); dropZone.textContent = 'Drop your .gltf or .glb file(s) here'; });
    dropZone.addEventListener('dragleave', () => dropZone.textContent = 'Drag and Drop your .gltf or .glb file(s) here');
    dropZone.addEventListener('drop', async e => {
        e.preventDefault();
        droppedFileBlobs.clear(); // Clear previous files
        let mainModelFile = null;

        // Function to recursively read directory entries
        async function readDroppedFiles(entry, path) {
            if (entry.isFile) {
                const file = await new Promise(resolve => entry.file(resolve));
                const fullPath = path ? `${path}/${file.name}` : file.name;
                droppedFileBlobs.set(fullPath, file);
                console.log(`[Drop Handler] Dropped file: ${fullPath}`); // Debugging
                if (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb')) {
                    mainModelFile = file;
                }
            } else if (entry.isDirectory) {
                const directoryReader = entry.createReader();
                const entries = await new Promise(resolve => directoryReader.readEntries(resolve));
                for (const subEntry of entries) {
                    await readDroppedFiles(subEntry, path ? `${path}/${entry.name}` : entry.name);
                }
            }
        }

        // Check if DataTransferItem.webkitGetAsEntry is available (for folder drops)
        if (e.dataTransfer.items && e.dataTransfer.items.length > 0 && e.dataTransfer.items[0].webkitGetAsEntry) {
            console.log("[Drop Handler] Using webkitGetAsEntry for folder drop.");
            for (let i = 0; i < e.dataTransfer.items.length; i++) {
                const item = e.dataTransfer.items[i];
                const entry = item.webkitGetAsEntry();
                if (entry) {
                    await readDroppedFiles(entry, ''); // Start recursive read from root
                }
            }
        } else {
            console.log("[Drop Handler] Falling back to flat file drop (webkitGetAsEntry not available or not a folder drop).");
            // Fallback for browsers that don't support webkitGetAsEntry or if only files are dropped
            for (let i = 0; i < e.dataTransfer.files.length; i++) {
                const file = e.dataTransfer.files[i];
                droppedFileBlobs.set(file.name, file);
                console.log(`[Drop Handler] Dropped file (flat): ${file.name}`); // Debugging
                if (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb')) {
                    mainModelFile = file;
                }
            }
        }

        if (mainModelFile) {
            uploadedFile = mainModelFile; // Set the main model file
            validateFile(uploadedFile); // Validate and proceed
            console.log("[Drop Handler] All dropped files (keys):", Array.from(droppedFileBlobs.keys()));
        } else {
            loadingMsg.textContent = '❌ No .gltf or .glb file found among dropped items!';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            uploadedFile = null;
        }
    });

    fileInput.addEventListener('change', () => {
        // For file input, we only get one file, so it's simpler
        if (fileInput.files.length > 0) {
            droppedFileBlobs.clear();
            const file = fileInput.files[0];
            droppedFileBlobs.set(file.name, file);
            uploadedFile = file;
            validateFile(uploadedFile);
            console.log("[File Input] Dropped file (keys):", Array.from(droppedFileBlobs.keys()));
        }
    });

    // Attach event listener for the "Load Model & Go to Editor" button
    loadEditorButton.addEventListener('click', goToEditor); // Correctly attach event listener

    function validateFile(file) {
        if (file && (file.name.toLowerCase().endsWith('.gltf') || file.name.toLowerCase().endsWith('.glb'))) {
            loadingMsg.textContent = `Loading ${file.name}...`;
            loadingMsg.style.display = 'block';
            // goToEditor will be called by the button click, or automatically if drag/drop leads to valid file
        } else {
            loadingMsg.textContent = '❌ Unsupported file type! Please upload a .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            uploadedFile = null;
        }
    }

    function goToEditor() {
        if (!uploadedFile) {
            addMessageToLog('System', "Please upload a valid .gltf or .glb file before continuing.");
            return;
        }

        uploadPage.classList.remove('page-active');
        uploadPage.classList.add('page-inactive');

        editorPage.classList.remove('page-inactive');
        editorPage.classList.add('page-active');

        loadingMsg.style.display = 'block';
        loadModel(uploadedFile); // Load model after transition
    }

    function goBack() {
        editorPage.classList.remove('page-active');
        editorPage.classList.add('page-inactive');

        uploadPage.classList.remove('page-inactive');
        uploadPage.classList.add('page-active');

        stopVoiceAssist(); // Ensure voice assist is stopped when going back

        // Dispose of Three.js resources when navigating back
        if (scene) {
            scene.traverse(function (object) {
                if (object.isMesh) {
                    if (object.geometry) object.geometry.dispose();
                    if (object.material) {
                        if (Array.isArray(object.material)) {
                            object.material.forEach(material => material.dispose());
                        } else {
                            object.material.dispose();
                        }
                    }
                }
            });
            scene = null;
        }
        if (renderer) {
            renderer.dispose();
            renderer = null;
        }
        if (controls) {
            controls.dispose();
            controls = null;
        }
        window.removeEventListener('resize', onWindowResize, false);
        clearSelection(); // Clear any active selection
        if (cadCanvas) { // Use cadCanvas reference
            cadCanvas.removeEventListener('mousedown', onCanvasClick, false);
            cadCanvas.removeEventListener('touchstart', onCanvasClick, false);
        }
        uploadedFile = null; // Clear the uploaded file
        droppedFileBlobs.clear(); // Clear the map of dropped files
        dropZone.style.borderColor = '#aaa'; // Reset drop zone style
        dropZone.textContent = 'Drag and Drop your .gltf or .glb file(s) here'; // Reset drop zone text
        loadingMsg.style.display = 'none'; // Hide loading message
        loadingMsg.style.color = ''; // Reset color
    }

    // --- Three.js Scene Setup and Model Loading ---
    function initScene() {
        scene = new THREE.Scene();
        scene.background = new THREE.Color(0x222222); // Dark background

        const viewerDiv = cadCanvas.parentElement;
        const width = viewerDiv.clientWidth;
        const height = viewerDiv.clientHeight;

        camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
        camera.position.set(0, 0, 50); // Initial camera position

        renderer = new THREE.WebGLRenderer({ canvas: cadCanvas, antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(width, height);
        renderer.xr.enabled = true; // Enable WebXR for VR

        // OrbitControls is now imported as a module
        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.25;

        // Lighting
        const ambientLight = new THREE.AmbientLight(0x404040); // Soft white light
        scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
        directionalLight.position.set(1, 1, 1).normalize();
        scene.add(directionalLight);

        // VR Button is now imported as a module
        // document.body.appendChild(VRButton.createButton(renderer));

        // Raycasting for selection
        raycaster = new THREE.Raycaster();
        mouse = new THREE.Vector2();

        // Attach event listeners for selection after renderer is set up
        renderer.domElement.addEventListener('mousedown', onCanvasClick, false);
        renderer.domElement.addEventListener('touchstart', onCanvasClick, false);

        animate(); // Start the animation loop
    }

    function animate() {
        // Use renderer.setAnimationLoop for WebXR compatibility
        renderer.setAnimationLoop(() => {
            controls.update();
            renderer.render(scene, camera);
        });
    }

    function loadModel(file) {
        console.log(`[loadModel] Attempting to load file: ${file.name}`);
        const loader = new GLTFLoader();

        loader.manager.setURLModifier((url, path) => {
            // debugger; // Pause execution here to inspect 'url', 'path', and 'droppedFileBlobs'

            console.log(`[URLModifier] Requested URL: "${url}", Path: "${path}"`);

            // 1. Try to get a clean relative path from the full URL
            let resolvedPath = url;
            try {
                const urlObj = new URL(url);
                resolvedPath = urlObj.pathname.substring(1); // Remove leading slash
                const filenameParam = urlObj.searchParams.get('filename');
                if (filenameParam) {
                    resolvedPath = filenameParam;
                }
            } catch (e) {
                // If URL constructor fails, assume it's already a relative path or filename
                resolvedPath = url;
            }

            // Normalize path separators for consistency (e.g., Windows vs. Unix paths)
            resolvedPath = resolvedPath.replace(/\\/g, '/');

            // 2. Check if the exact resolvedPath exists in our dropped files
            if (droppedFileBlobs.has(resolvedPath)) {
                const blob = droppedFileBlobs.get(resolvedPath);
                const blobUrl = URL.createObjectURL(blob);
                console.log(`[URLModifier] Found "${resolvedPath}" (exact match), creating Blob URL: ${blobUrl}`);
                return blobUrl;
            }

            // 3. If not found by full path, try just the filename (common for textures in GLTF)
            const fileNameOnly = resolvedPath.substring(resolvedPath.lastIndexOf('/') + 1);
            if (droppedFileBlobs.has(fileNameOnly)) {
                const blob = droppedFileBlobs.get(fileNameOnly);
                const blobUrl = URL.createObjectURL(blob);
                console.log(`[URLModifier] Found "${fileNameOnly}" (filename only match), creating Blob URL: ${blobUrl}`);
                return blobUrl;
            }

            // 4. Try matching the 'path' argument provided by GLTFLoader (it's often the base path)
            // Combine 'path' with fileNameOnly if 'path' is provided and not empty
            if (path && path !== '') {
                const combinedPath = `${path}${fileNameOnly}`;
                if (droppedFileBlobs.has(combinedPath)) {
                    const blob = droppedFileBlobs.get(combinedPath);
                    const blobUrl = URL.createObjectURL(blob);
                    console.log(`[URLModifier] Found "${combinedPath}" (combined path match), creating Blob URL: ${blobUrl}`);
                    return blobUrl;
                }
            }


            console.warn(`[URLModifier] GLTFLoader could not find referenced file: "${url}" (tried "${resolvedPath}", "${fileNameOnly}", and potentially combined paths). Falling back to original URL.`);
            return url; // Fallback to original URL
        });

        if (file.name.toLowerCase().endsWith('.glb')) {
            console.log(`[loadModel] Handling .glb file: ${file.name}`);
            const reader = new FileReader();
            reader.onload = (event) => {
                console.log(`[FileReader] .glb file read successfully.`);
                const contents = event.target.result;
                loader.parse(contents, '', (gltf) => {
                    console.log(`[GLTFLoader] .glb parsing successful.`);
                    // Remove existing model if any
                    if (mesh) {
                        scene.remove(mesh);
                        mesh.traverse(obj => {
                            if (obj.isMesh) {
                                if (obj.geometry) obj.geometry.dispose();
                                if (obj.material) {
                                    if (Array.isArray(obj.material)) {
                                        obj.material.forEach(m => m.dispose());
                                    } else {
                                        obj.material.dispose();
                                    }
                                }
                            }
                        });
                    }
                    clearSelection(); // Clear any previous selection

                    mesh = gltf.scene; // The glTF scene is the main container for all objects
                    scene.add(mesh);

                    // Center and scale the model
                    const bbox = new THREE.Box3().setFromObject(mesh);
                    const center = bbox.getCenter(new THREE.Vector3());
                    mesh.position.sub(center); // Center the model's group

                    const size = bbox.getSize(new THREE.Vector3());
                    const maxDim = Math.max(size.x, size.y, size.z);
                    const desiredMaxDim = 40; // Target size for the model in the scene
                    const scaleFactor = desiredMaxDim / maxDim;
                    mesh.scale.set(scaleFactor, scaleFactor, scaleFactor);

                    // Adjust camera to fit the new model
                    const newBbox = new THREE.Box3().setFromObject(mesh); // Get bbox after scaling
                    const newSize = newBbox.getSize(new THREE.Vector3());
                    const newMaxDim = Math.max(newSize.x, newSize.y, newSize.z);
                    camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
                    camera.lookAt(0, 0, 0);
                    controls.update(); // Update controls after camera change

                    loadingMsg.style.display = 'none';
                    addMessageToLog('System', `Model '${file.name}' loaded successfully.`);
                    speakResponse(`Model loaded successfully.`);

                }, (error) => {
                    console.error('[GLTFLoader] Error parsing GLB model:', error);
                    loadingMsg.textContent = 'Error parsing GLB model. Check console for details.';
                    loadingMsg.style.color = 'red';
                    speakResponse('Error parsing GLB model.');
                });
            };
            reader.onerror = (error) => {
                console.error('[FileReader] Error reading GLB file:', error);
                loadingMsg.textContent = 'Error reading GLB file. Check console for details.';
                loadingMsg.style.color = 'red';
                speakResponse('Error reading GLB file.');
            };
            reader.readAsArrayBuffer(file);
        } else if (file.name.toLowerCase().endsWith('.gltf')) {
            console.log(`[loadModel] Handling .gltf file: ${file.name}`);
            const blobUrl = URL.createObjectURL(file);
            console.log(`[loadModel] Created Blob URL for main GLTF file: ${blobUrl}`);

            loader.load(blobUrl, (gltf) => {
                console.log(`[GLTFLoader] .gltf loading successful.`);
                // Remove existing model if any
                if (mesh) {
                    scene.remove(mesh);
                    mesh.traverse(obj => {
                        if (obj.isMesh) {
                            if (obj.geometry) obj.geometry.dispose();
                            if (obj.material) {
                                if (Array.isArray(obj.material)) {
                                    obj.material.forEach(m => m.dispose());
                                } else {
                                    obj.material.dispose();
                                }
                            }
                        }
                    });
                }
                clearSelection(); // Clear any previous selection

                mesh = gltf.scene; // The glTF scene is the main container for all objects
                scene.add(mesh);

                // Center and scale the model
                const bbox = new THREE.Box3().setFromObject(mesh);
                const center = bbox.getCenter(new THREE.Vector3());
                mesh.position.sub(center); // Center the model's group

                const size = bbox.getSize(new THREE.Vector3());
                const maxDim = Math.max(size.x, size.y, size.z);
                const desiredMaxDim = 40; // Target size for the model in the scene
                const scaleFactor = desiredMaxDim / maxDim;
                mesh.scale.set(scaleFactor, scaleFactor, scaleFactor);

                // Adjust camera to fit the new model
                const newBbox = new THREE.Box3().setFromObject(mesh); // Get bbox after scaling
                const newSize = newBbox.getSize(new THREE.Vector3());
                const newMaxDim = Math.max(newSize.x, newSize.y, newSize.z);
                camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
                camera.lookAt(0, 0, 0);
                controls.update(); // Update controls after camera change

                loadingMsg.style.display = 'none';
                addMessageToLog('System', `Model '${file.name}' loaded successfully.`);
                speakResponse(`Model loaded successfully.`);

                URL.revokeObjectURL(blobUrl); // Clean up the Blob URL

            }, (xhr) => {
                // Progress during loading
                console.log(`[GLTFLoader] Progress for ${file.name}: ${Math.round(xhr.loaded / xhr.total * 100)}%`);
                loadingMsg.textContent = `Loading ${file.name}: ${Math.round(xhr.loaded / xhr.total * 100)}%`;
            }, (error) => {
                console.error('[GLTFLoader] Error loading GLTF model:', error);
                loadingMsg.textContent = 'Error loading GLTF model. Ensure all associated files (.bin, textures) are dropped together.';
                loadingMsg.style.color = 'red';
                speakResponse('Error loading GLTF model. Please ensure all associated files are dropped together.');
                URL.revokeObjectURL(blobUrl); // Clean up the Blob URL on error
            });
        } else {
            // This case should ideally be caught by validateFile, but as a fallback
            loadingMsg.textContent = '❌ Unsupported file type! Please upload a .gltf or .glb file.';
            loadingMsg.style.color = 'red';
            loadingMsg.style.display = 'block';
            speakResponse('Unsupported file type.');
        }
    }

    window.addEventListener('resize', onWindowResize, false);

    function onWindowResize() {
        const viewerDiv = cadCanvas.parentElement;
        const width = viewerDiv.clientWidth;
        const height = viewerDiv.clientHeight;

        if (width > 0 && height > 0) {
            camera.aspect = width / height;
            camera.updateProjectionMatrix();
            renderer.setSize(width, height);
            controls.update();
        }
    }

    // Initialize scene when the window loads
    window.onload = () => {
        initScene();
        initializeSpeechSynthesis();
    };

    // --- CAD Editor Functions ---
    // Note: removeObject, resetView, showDesignInfo are updated to handle selectedObject or mesh
    function removeObject() {
        let targetObject = selectedObject || mesh; // Target selected object, or the whole model
        if (targetObject) {
            scene.remove(targetObject);
            targetObject.traverse(obj => { // Dispose resources
                if (obj.isMesh) {
                    if (obj.geometry) obj.geometry.dispose();
                    if (obj.material) {
                        if (Array.isArray(obj.material)) {
                            obj.material.forEach(m => m.dispose());
                        } else {
                            obj.material.dispose();
                        }
                    }
                }
            });
            if (targetObject === mesh) { // If main model was removed
                mesh = null;
                addMessageToLog('AI', "Model removed.");
                speakResponse("Model removed.");
                // Go back to upload page if main model is removed
                goBack(); // This will also clear selection
            } else { // If a specific part was removed
                addMessageToLog('AI', `Part '${targetObject.name || 'unnamed part'}' removed.`);
                speakResponse(`Part removed.`);
                clearSelection(); // Clear selection after removal
            }
        } else {
            addMessageToLog('AI', "No object or part to remove.");
            speakResponse("No object or part to remove.");
        }
    }

    function resetView() {
        if (mesh) { // Resetting view always applies to the whole loaded model
            mesh.rotation.set(0, 0, 0); // Reset rotation of the main model
            mesh.position.set(0, 0, 0); // Reset position of the main model

            // Recenter and re-frame camera
            const bbox = new THREE.Box3().setFromObject(mesh);
            const center = bbox.getCenter(new THREE.Vector3());
            mesh.position.sub(center); // Center the model's group

            const size = bbox.getSize(new THREE.Vector3());
            const maxDim = Math.max(size.x, size.y, size.z);
            camera.position.set(newMaxDim * 1.5, newMaxDim * 1.5, newMaxDim * 1.5);
            camera.lookAt(0, 0, 0);
            controls.update();
            addMessageToLog('AI', "View reset.");
            speakResponse("View reset.");
        } else {
            addMessageToLog('AI', "No model to reset view for.");
            speakResponse("No model to reset view for.");
        }
    }

    function showDesignInfo() {
        let targetObject = selectedObject || mesh; // Get info for selected object or whole model
        if (!targetObject) {
            addMessageToLog('AI', "No design loaded or part selected.");
            speakResponse("No design loaded or part selected.");
            return;
        }
        const bbox = new THREE.Box3().setFromObject(targetObject);
        const size = new THREE.Vector3();
        bbox.getSize(size);
        const info = `Name: ${targetObject.name || 'Unnamed'}\n` +
                     `Width: ${size.x.toFixed(2)}\nHeight: ${size.y.toFixed(2)}\nDepth: ${size.z.toFixed(2)}\n` +
                     `Position: X:${targetObject.position.x.toFixed(2)}, Y:${targetObject.position.y.toFixed(2)}, Z:${targetObject.position.z.toFixed(2)}`;
        addMessageToLog('AI', info.replace(/\n/g, ', '));
        speakResponse(info);
    }

    // --- Raycasting and Selection ---
    function onCanvasClick(event) {
        // Calculate mouse position in normalized device coordinates (-1 to +1)
        const rect = renderer.domElement.getBoundingClientRect();
        if (event.changedTouches) { // Handle touch events
            mouse.x = ((event.changedTouches[0].clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.changedTouches[0].clientY - rect.top) / rect.height) * 2 + 1;
        } else { // Handle mouse events
            mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
            mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
        }

        raycaster.setFromCamera(mouse, camera);

        // Intersect with all children of the main loaded glTF scene object (`mesh`)
        // This allows selecting individual parts/meshes if the glTF has them
        const intersects = raycaster.intersectObjects(mesh ? mesh.children : [], true); // Only intersect if mesh exists

        if (intersects.length > 0) {
            let clickedObject = null;
            for (const intersect of intersects) {
                // Ensure it's a visible mesh and not just a group or part of the background
                if (intersect.object.isMesh && intersect.object.visible && intersect.object.material) {
                    clickedObject = intersect.object;
                    break;
                }
            }

            if (clickedObject) {
                if (selectedObject && selectedObject !== clickedObject) {
                    // Restore original color of previously selected object if it's different
                    restoreOriginalColor(selectedObject);
                }

                if (selectedObject !== clickedObject) { // If a new object is selected
                    selectedObject = clickedObject;
                    storeAndHighlight(selectedObject);
                    addMessageToLog('System', `Object '${selectedObject.name || 'unnamed object'}' selected.`);
                    speakResponse(`Object selected.`);
                } else { // If the same object is clicked again, deselect it
                    clearSelection();
                }
            }
        } else {
            clearSelection(); // If clicked outside, clear selection
        }
    }

    function storeAndHighlight(object) {
        if (Array.isArray(object.material)) {
            object.material.forEach((m, index) => {
                originalColors.set(`${object.uuid}-${index}`, m.color.getHex());
                m.color.set(0x00ff00); // Green highlight
            });
        } else if (object.material) {
            originalColors.set(object.uuid, object.material.color.getHex());
            object.material.color.set(0x00ff00); // Green highlight
        }
    }

    function restoreOriginalColor(object) {
        if (Array.isArray(object.material)) {
            object.material.forEach((m, index) => {
                const oldOriginalColor = originalColors.get(`${object.uuid}-${index}`);
                if (oldOriginalColor !== undefined) {
                    m.color.set(oldOriginalColor);
                }
            });
        } else if (object.material) {
            const oldOriginalColor = originalColors.get(object.uuid);
            if (oldOriginalColor !== undefined) {
                object.material.color.set(oldOriginalColor);
            }
        }
        originalColors.delete(object.uuid); // Clean up map entry
    }

    function clearSelection() {
        if (selectedObject) {
            restoreOriginalColor(selectedObject);
            selectedObject = null;
            addMessageToLog('System', 'Selection cleared.');
            speakResponse('Selection cleared.');
        }
    }

    // --- AI Interaction Panel Functions ---
    function addMessageToLog(sender, message) {
        const p = document.createElement('p');
        p.textContent = `${sender}: ${message}`;
        p.classList.add(sender === 'User' ? 'user-message' : (sender === 'AI' ? 'ai-response' : 'system-message'));
        aiLog.appendChild(p);
        aiLog.scrollTop = aiLog.scrollHeight;
    }

    sendTextCommandBtn.addEventListener('click', () => {
        const command = textCommandInput.value.trim();
        if (command) {
            addMessageToLog('User', command);
            processAICommand(command);
            textCommandInput.value = '';
        }
    });

    textCommandInput.addEventListener('keypress', (event) => {
        if (event.key === 'Enter') {
            sendTextCommandBtn.click();
        }
    });

    // --- AI Voice Assist Functions ---
    voiceAssistBtn.addEventListener('click', toggleVoiceAssist);

    function initializeSpeechRecognition() {
        if (!('webkitSpeechRecognition' in window)) {
            addMessageToLog('System', "Speech recognition not supported in this browser. Please use Google Chrome.");
            return null;
        }
        const newRecognition = new webkitSpeechRecognition();
        newRecognition.continuous = true;
        newRecognition.interimResults = false;
        newRecognition.lang = 'en-US';
        return newRecognition;
    }

    function initializeSpeechSynthesis() {
        if (!('speechSynthesis' in window)) {
            addMessageToLog('System', "Speech synthesis not supported in this browser.");
            return null;
        }
        return window.speechSynthesis;
    }

    function speakResponse(text) {
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }
        synth.cancel();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'en-US';
        utterance.onend = () => {
            console.log('Speech synthesis ended');
            if (isVoiceAssistActive && recognition && !synth.speaking) {
                setTimeout(() => {
                    addMessageToLog('System', "Listening...");
                    recognition.start();
                }, 1500);
            }
        };
        utterance.onerror = (event) => {
            console.error('Speech synthesis error:', event);
            addMessageToLog('System', "Error speaking response.");
        };
        synth.speak(utterance);
    }

    function toggleVoiceAssist() {
        if (!mesh) {
            addMessageToLog('AI', "Please load a 3D model first.");
            speakResponse("Please load a 3D model first.");
            return;
        }

        if (!recognition) {
            recognition = initializeSpeechRecognition();
            if (!recognition) return;
        }
        if (!synth) {
            synth = initializeSpeechSynthesis();
            if (!synth) return;
        }

        if (isVoiceAssistActive) {
            stopVoiceAssist();
            speakResponse("Voice assist stopped. Goodbye!");
        } else {
            isVoiceAssistActive = true;
            voiceAssistBtn.classList.add('active-voice-btn');
            voiceAssistBtn.innerHTML = '❌ Stop AI Voice';
            aiInteractionPanel.classList.add('active');
            addMessageToLog('System', "Starting voice assist...");

            speakResponse("Hi, what can I help you with?");
        }

        recognition.onstart = function () {
            addMessageToLog('System', "Listening...");
            console.log('Speech recognition started');
        };

        recognition.onresult = function (event) {
            const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
            addMessageToLog('User', transcript);
            addMessageToLog('System', "Processing voice command...");
            console.log('Speech recognized:', transcript);

            recognition.stop();
            processAICommand(transcript);
        };

        recognition.onerror = function (event) {
            console.error('Speech recognition error:', event);
            let errorMessage = "An unknown speech recognition error occurred.";
            if (event.error === 'not-allowed') {
                errorMessage = "Microphone access denied. Please allow microphone access in your browser settings.";
            } else if (event.error === 'no-speech') {
                errorMessage = "No speech detected. Please try speaking louder or clearer.";
            } else if (event.error) {
                errorMessage = `Speech error: ${event.error}. Please try again.`;
            }
            addMessageToLog('System', errorMessage);
            speakResponse(errorMessage);
            stopVoiceAssist();
        };

        recognition.onend = function () {
            console.log('Speech recognition ended');
        };
    }

    function stopVoiceAssist() {
        isVoiceAssistActive = false;
        if (recognition && typeof recognition.stop === 'function') {
            recognition.stop();
        }
        if (synth && typeof synth.cancel === 'function') {
            synth.cancel();
        }
        aiInteractionPanel.classList.remove('active');
        voiceAssistBtn.classList.remove('active-voice-btn');
        voiceAssistBtn.innerHTML = '🧠 AI Voice Assist';
        addMessageToLog('System', "Voice assist stopped.");
    }

    // --- AI Command Processing (Core Logic) ---
    async function processAICommand(command) {
        // Handle pre-defined UI commands first
        if (command.includes("select object") || command.includes("select part")) {
            if (selectedObject) {
                speakResponse("An object is already selected. Click on a different part to change selection or click outside to clear.");
            } else if (mesh) {
                speakResponse("Please click on a part of the model to select it.");
            } else {
                speakResponse("No model loaded to select.");
            }
            return;
        } else if (command.includes("clear selection") || command.includes("deselect")) {
            clearSelection();
            speakResponse("Selection cleared.");
            return;
        }

        try {
            const aiReply = await sendToAI(command);
            console.log("Raw AI response from backend:", aiReply);

            let resultData;
            try {
                resultData = JSON.parse(aiReply.content);
                console.log("Parsed AI command:", resultData);
            } catch (e) {
                resultData = { action: 'conversational', value: aiReply.content };
                console.log("Parsed AI conversational response:", resultData);
            }

            if (resultData && typeof resultData === 'object' && resultData.action) {
                let target = selectedObject || mesh; // Target the selected object, or the whole model if nothing is selected

                // Handle cases where an action requires a selected object but none is present
                const requiresSelection = ['rotateSelected', 'scaleSelected', 'translateSelected', 'colorSelected', 'hideSelected', 'showSelected', 'duplicateSelected', 'removeSelected'];
                if (requiresSelection.includes(resultData.action) && !selectedObject) {
                    addMessageToLog('AI', "Please select a part of the model first to perform that action.");
                    speakResponse("Please select a part of the model first to perform that action.");
                    return;
                }

                switch (resultData.action) {
                    case 'rotate':
                    case 'rotateSelected':
                        if (target && typeof resultData.value === 'number') {
                            // THREE.MathUtils.degToRad is now directly available via THREE
                            target.rotation.y += THREE.MathUtils.degToRad(resultData.value);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} rotated by ${resultData.value} degrees.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} rotated by ${resultData.value} degrees.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't rotate. Please specify a valid degree value or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't rotate.");
                        }
                        break;
                    case 'scale':
                    case 'scaleSelected':
                        if (target && typeof resultData.value === 'number' && resultData.value > 0) {
                            target.scale.set(resultData.value, resultData.value, resultData.value);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} scaled by a factor of ${resultData.value}.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} scaled by a factor of ${resultData.value}.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't scale. Please specify a positive scale factor or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't scale.");
                        }
                        break;
                    case 'translate':
                    case 'translateSelected':
                        if (target && typeof resultData.value === 'object' &&
                            !isNaN(resultData.value.x) && !isNaN(resultData.value.y) && !isNaN(resultData.value.z)) {
                            target.position.x += resultData.value.x || 0;
                            target.position.y += resultData.value.y || 0;
                            target.position.z += resultData.value.z || 0;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} moved by X:${resultData.value.x || 0}, Y:${resultData.value.y || 0}, Z:${resultData.value.z || 0} units.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} moved.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't move. Please specify valid X, Y, and Z values or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't move.");
                        }
                        break;
                    case 'color':
                    case 'colorSelected':
                        if (target && typeof resultData.value === 'string' && /^#([0-9A-F]{3}){1,2}$/i.test(resultData.value)) {
                            if (Array.isArray(target.material)) {
                                target.material.forEach(m => m.color.set(resultData.value));
                            } else if (target.material) {
                                target.material.color.set(resultData.value);
                            }
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} color changed to ${resultData.value}.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} color changed.`);
                        } else {
                            addMessageToLog('AI', "Sorry, I couldn't change the color. Please provide a valid hexadecimal color code, or ensure a model is loaded/selected.");
                            speakResponse("Sorry, I couldn't change the color.");
                        }
                        break;
                    case 'hide':
                    case 'hideSelected':
                        if (target) {
                            target.visible = false;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} is now hidden.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} is now hidden.`);
                            if (selectedObject === target) clearSelection(); // Deselect if hidden
                        } else {
                            addMessageToLog('AI', "No model or part to hide.");
                            speakResponse("No model or part to hide.");
                        }
                        break;
                    case 'show':
                    case 'showSelected':
                        if (target) {
                            target.visible = true;
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} is now visible.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} is now visible.`);
                        } else {
                            addMessageToLog('AI', "No model or part to show.");
                            speakResponse("No model or part to show.");
                        }
                        break;
                    case 'duplicate':
                    case 'duplicateSelected':
                        if (target) {
                            const newObject = target.clone();
                            newObject.position.x += 10; // Offset slightly
                            newObject.position.y += 10;
                            scene.add(newObject);
                            addMessageToLog('AI', `${selectedObject ? 'Selected part' : 'Model'} duplicated.`);
                            speakResponse(`${selectedObject ? 'Selected part' : 'Model'} duplicated.`);
                        } else {
                            addMessageToLog('AI', "No model or part to duplicate.");
                            speakResponse("No model or part to duplicate.");
                        }
                        break;
                    case 'removeObject':
                    case 'removeSelected': // AI might send this for selected object
                        removeObject(); // This function now handles selectedObject vs mesh
                        break;
                    case 'resetView': // This command always applies to the whole scene
                        resetView();
                        break;
                    case 'designInfo': // This command always applies to selected or whole model
                        showDesignInfo();
                        break;
                    case 'conversational':
                        let responseText = resultData.value || resultData.message;
                        if (responseText) {
                            addMessageToLog('AI', responseText);
                            speakResponse(responseText);
                        } else {
                            addMessageToLog('AI', "I received a conversational response but it was empty.");
                            speakResponse("I received a conversational response but it was empty.");
                        }
                        break;
                    case 'error':
                        addMessageToLog('AI', `An AI error occurred: ${resultData.value}. Please try again.`);
                        speakResponse("An error occurred with the AI. Please try again.");
                        console.error("AI returned an error action:", resultData.value);
                        break;
                    default:
                        addMessageToLog('AI', "The AI sent an unrecognized command. Please try again.");
                        speakResponse("The AI sent an unrecognized command. Please try again.");
                        console.warn("AI sent unrecognized action:", resultData.action);
                        break;
                }
            } else {
                addMessageToLog('AI', "I received an unexpected AI response. Please try again.");
                speakResponse("I received an unexpected AI response. Please try again.");
                console.error("Unexpected AI response format:", resultData);
            }
        } catch (error) {
            console.error("Error processing AI command:", error);
            addMessageToLog('AI', "I'm sorry, I encountered an error while processing your command. Please try again.");
            speakResponse("I'm sorry, I encountered an error. Please try again.");
        }
    }

    async function sendToAI(prompt) {
        sendTextCommandBtn.disabled = true;
        textCommandInput.disabled = true;
        addMessageToLog('System', 'AI is thinking...');

        const payload = {
            prompt: prompt
        };

        try {
            const response = await fetch('https://mingyu.onrender.com/api/ai', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(`Backend error: ${errorData.message || response.statusText}`);
            }

            const result = await response.json();
            return result;

        } catch (error) {
            console.error("Error communicating with backend AI:", error);
            return { content: `Failed to communicate with AI: ${error.message}` };
        } finally {
            sendTextCommandBtn.disabled = false;
            textCommandInput.disabled = false;
            const lastLogMessage = aiLog.lastChild;
            if (lastLogMessage && lastLogMessage.textContent.includes('AI is thinking...')) {
                aiLog.removeChild(lastLogMessage);
            }
        }
    }
</script>
</body>
</html>
